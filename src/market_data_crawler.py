import requests
import pandas as pd
import logging
from datetime import datetime
import config
from bs4 import BeautifulSoup
import time
import random
from openpyxl import load_workbook
from openpyxl.styles import Alignment
from openpyxl import Workbook
import zipfile

import platform
from datetime import datetime
import os
import sys
import threading
# ç§»é™¤signalæ¨¡å—å¯¼å…¥ï¼Œå› ä¸ºå®ƒåªèƒ½åœ¨ä¸»çº¿ç¨‹ä¸­ä½¿ç”¨

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.firefox import GeckoDriverManager
from webdriver_manager.microsoft import EdgeChromiumDriverManager
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, WebDriverException
from selenium.webdriver import ActionChains

import time
import concurrent.futures
from functools import wraps
import fcntl

# åœ¨è„šæœ¬å¼€å¤´å¯¼å…¥å¹¶é…ç½®è¿æ¥æ± 
from urllib3.poolmanager import PoolManager
import urllib3

# ç¦ç”¨æ‰€æœ‰urllib3è­¦å‘Š
urllib3.disable_warnings()

# å¢åŠ è¿æ¥æ± å¤§å°å’Œè¿æ¥æ•°
class CustomPoolManager(PoolManager):
    def __init__(self, **kwargs):
        kwargs.setdefault('num_pools', 200)
        kwargs.setdefault('maxsize', 200)
        super().__init__(**kwargs)

# æ›¿æ¢é»˜è®¤è¿æ¥æ± ç®¡ç†å™¨
urllib3.PoolManager = CustomPoolManager

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ·»åŠ å½©è‰²æ—¥å¿—è¾“å‡º
class ColoredFormatter(logging.Formatter):
    """è‡ªå®šä¹‰å½©è‰²æ—¥å¿—æ ¼å¼åŒ–å™¨"""

    COLORS = {
        'DEBUG': '\033[94m',     # è“è‰²
        'INFO': '\033[92m',      # ç»¿è‰²
        'WARNING': '\033[93m',   # é»„è‰²
        'ERROR': '\033[91m',     # çº¢è‰²
        'CRITICAL': '\033[91m\033[1m',  # çº¢è‰²åŠ ç²—
        'RESET': '\033[0m'       # é‡ç½®é¢œè‰²
    }

    def format(self, record):
        log_message = super().format(record)
        level_name = record.levelname
        if level_name in self.COLORS:
            return f"{self.COLORS[level_name]}{log_message}{self.COLORS['RESET']}"
        return log_message

def setup_logging(debug=False):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    level = logging.DEBUG if debug else logging.INFO

    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.setLevel(level)

    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(level)

    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    if os.name == 'posix':  # åœ¨ç±»Unixç³»ç»Ÿä¸Šå¯ç”¨å½©è‰²è¾“å‡º
        formatter = ColoredFormatter('%(message)s')
    else:
        formatter = logging.Formatter('%(message)s')

    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # æ–‡ä»¶å¤„ç†å™¨ - è¯¦ç»†æ—¥å¿—ä¿å­˜åˆ°æ–‡ä»¶
    file_handler = logging.FileHandler('market_data_crawler.log')
    file_handler.setLevel(level)

    # åˆ›å»ºlogsç›®å½•ä¸‹çš„æ—¥å¿—æ–‡ä»¶å¤„ç†å™¨
    # ç¡®ä¿logsç›®å½•å­˜åœ¨
    logs_dir = 'logs'
    if not os.path.exists(logs_dir):
        os.makedirs(logs_dir)

    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    logs_file_path = os.path.join(logs_dir, f'crawler_{timestamp}.log')

    # åˆ›å»ºlogsç›®å½•ä¸‹çš„æ–‡ä»¶å¤„ç†å™¨
    logs_file_handler = logging.FileHandler(logs_file_path)
    logs_file_handler.setLevel(level)
    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)

    # è®¾ç½®logsç›®å½•ä¸‹æ–‡ä»¶å¤„ç†å™¨æ ¼å¼
    logs_file_handler.setFormatter(file_formatter)
    logger.addHandler(logs_file_handler)

    # è®°å½•æ—¥å¿—å¯åŠ¨ä¿¡æ¯
    logger.info(f"æ—¥å¿—å·²é…ç½®ï¼šæ§åˆ¶å°ã€æ ¹ç›®å½•æ–‡ä»¶å’Œlogs/{os.path.basename(logs_file_path)}")

def log_execution_time(func):
    """è®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´çš„è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time
        # åªåœ¨DEBUGçº§åˆ«è®°å½•æ‰§è¡Œæ—¶é—´ï¼Œæˆ–è€…åœ¨å¤±è´¥æ—¶è®°å½•
        if result is None:
            logger.warning(f"{func.__name__} æ‰§è¡Œå¤±è´¥ï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
        else:
            logger.debug(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {elapsed_time:.2f} ç§’")
        return result
    return wrapper

def format_error_message(error):
    """æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯ï¼Œæå–å…³é”®éƒ¨åˆ†"""
    error_str = str(error)

    # å¦‚æœæ˜¯Seleniumé”™è¯¯ï¼Œæå–ä¸»è¦ä¿¡æ¯
    if "Session info" in error_str:
        # æå–ä¸»è¦é”™è¯¯ä¿¡æ¯ï¼Œå»é™¤å †æ ˆè·Ÿè¸ª
        main_error = error_str.split('Stacktrace:')[0].strip()
        return main_error

    # å¯¹äºå…¶ä»–é”™è¯¯ï¼Œç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯
    return error_str

def log_error(message, error=None, show_traceback=False):
    """ç»Ÿä¸€çš„é”™è¯¯æ—¥å¿—è®°å½•å‡½æ•°"""
    if error:
        error_msg = format_error_message(error)
        logger.error(f"{message}: {error_msg}")
        # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹è®°å½•å®Œæ•´å †æ ˆ
        if show_traceback:
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:", exc_info=True)
    else:
        logger.error(message)

def retry_on_timeout(func):
    """é‡è¯•è£…é¥°å™¨ï¼Œç”¨äºå¤„ç†è¶…æ—¶æƒ…å†µ"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        max_retries = 3
        retry_count = 0
        while retry_count < max_retries:
            try:
                return func(*args, **kwargs)
            except TimeoutException:
                retry_count += 1
                logger.warning(f"{func.__name__} ç¬¬{retry_count}æ¬¡å°è¯•è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•...")
                if retry_count >= max_retries:
                    logger.error(f"{func.__name__} å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œæ”¾å¼ƒå°è¯•")
                    return None
                # æ¯æ¬¡é‡è¯•å¢åŠ ç­‰å¾…æ—¶é—´
                time.sleep(2 * retry_count)
            except Exception as e:
                log_error(f"{func.__name__} å‘ç”Ÿé”™è¯¯", e, show_traceback=False)
                return None
    return wrapper

# ç¦ç”¨ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('selenium').setLevel(logging.WARNING)
logging.getLogger('webdriver_manager').setLevel(logging.WARNING)

# åˆ›å»ºä¸€ä¸ªç»Ÿè®¡å¯¹è±¡æ¥è·Ÿè¸ªæˆåŠŸå’Œå¤±è´¥çš„çˆ¬å–
class CrawlStats:
    """çˆ¬å–ç»Ÿè®¡ä¿¡æ¯ç±»ï¼Œç”¨äºè®°å½•çˆ¬å–æˆåŠŸã€å¤±è´¥å’Œè·³è¿‡çš„æ•°æ®"""

    def __init__(self):
        self.success = []
        self.failure = {}
        self.skipped = {}

    def add_success(self, name):
        self.success.append(name)

    def add_failure(self, name, reason):
        self.failure[name] = reason

    def add_skipped(self, name, reason):
        self.skipped[name] = reason

    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦å¹¶è¿”å›æ‘˜è¦æ–‡æœ¬"""
        # æ„å»ºæ‘˜è¦æ–‡æœ¬
        summary_lines = []
        summary_lines.append("ğŸ“Š çˆ¬å–ç»Ÿè®¡æ‘˜è¦")
        summary_lines.append("=" * 50)

        # æˆåŠŸæ•°æ®
        if self.success:
            summary_lines.append(f"âœ… æˆåŠŸ: {len(self.success)} é¡¹")
            # æ¯è¡Œæœ€å¤šæ˜¾ç¤º4ä¸ªé¡¹ç›®
            for i in range(0, len(self.success), 4):
                chunk = self.success[i:i+4]
                summary_lines.append(f"   {', '.join(chunk)}")

        # å¤±è´¥æ•°æ®
        if self.failure:
            summary_lines.append(f"\nâŒ å¤±è´¥: {len(self.failure)} é¡¹")
            for name, reason in self.failure.items():
                summary_lines.append(f"   {name}: {reason}")

        # è·³è¿‡æ•°æ®
        if self.skipped:
            summary_lines.append(f"\nâ­ï¸ è·³è¿‡: {len(self.skipped)} é¡¹")
            for name, reason in self.skipped.items():
                summary_lines.append(f"   {name}: {reason}")

        summary_lines.append("=" * 50)

        # å°†æ‘˜è¦æ–‡æœ¬è®°å½•åˆ°æ—¥å¿—
        for line in summary_lines:
            logger.info(line)

        # è¿”å›å®Œæ•´çš„æ‘˜è¦æ–‡æœ¬
        return "\n".join(summary_lines)

class MarketDataAnalyzer:
    _driver = None  # æ™®é€šWebDriverå®ä¾‹ï¼ˆå¯ç”¨JavaScriptï¼‰
    _driver_lock = threading.RLock()  # ç®€å•é”ï¼Œé˜²æ­¢å¹¶å‘åˆå§‹åŒ–

    _exchange_rate_driver = None  # ä¸“ç”¨äºæ±‡ç‡æ•°æ®çš„WebDriverå®ä¾‹ï¼ˆç¦ç”¨JavaScriptï¼‰
    _exchange_rate_driver_lock = threading.RLock()  # æ±‡ç‡æ•°æ®WebDriverçš„é”

    _daily_driver = None  # ä¸“ç”¨äºæ—¥é¢‘æ•°æ®çš„WebDriverå®ä¾‹
    _daily_driver_lock = threading.RLock()  # æ—¥é¢‘æ•°æ®WebDriverçš„é”

    _monthly_driver = None  # ä¸“ç”¨äºæœˆåº¦æ•°æ®çš„WebDriverå®ä¾‹
    _monthly_driver_lock = threading.RLock()  # æœˆåº¦æ•°æ®WebDriverçš„é”

    _instance = None  # æ·»åŠ å•ä¾‹å®ä¾‹å˜é‡

    def __init__(self):
        print("åˆå§‹åŒ–å¸‚åœºæ•°æ®åˆ†æå™¨...")
        # ä¸å†é¢„å…ˆåˆå§‹åŒ–WebDriverï¼Œè€Œæ˜¯åœ¨éœ€è¦æ—¶æŒ‰éœ€åˆ›å»º
        # åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­ä¸ä½¿ç”¨ä¿¡å·å¤„ç†
        # å› ä¸ºä¿¡å·å¤„ç†åªèƒ½åœ¨ä¸»çº¿ç¨‹ä¸­ä½¿ç”¨

        # å•ä¾‹æ¨¡å¼ï¼Œä¿å­˜å®ä¾‹å¼•ç”¨
        MarketDataAnalyzer._instance = self

    # ç§»é™¤ä¿¡å·å¤„ç†æ–¹æ³•ï¼Œå› ä¸ºå®ƒåªèƒ½åœ¨ä¸»çº¿ç¨‹ä¸­ä½¿ç”¨

    def _init_driver(self, disable_javascript=False):
        """
        ä¼˜åŒ–çš„WebDriveråˆå§‹åŒ–æ–¹æ³•

        Args:
            disable_javascript: æ˜¯å¦ç¦ç”¨JavaScriptï¼Œé»˜è®¤ä¸ºFalse
        """
        if disable_javascript:
            logger.info("å¼€å§‹åˆå§‹åŒ–WebDriverWithDisableJavascript")
        else:
            logger.info("å¼€å§‹åˆå§‹åŒ–WebDriver")


        import os  # ç¡®ä¿osæ¨¡å—åœ¨å‡½æ•°å†…å¯ç”¨
        system = platform.system()

        # é€šç”¨é€‰é¡¹
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--no-sandbox')
        options.add_argument('--log-level=3')  # ä»…æ˜¾ç¤ºè‡´å‘½é”™è¯¯
        options.add_argument('--start-maximized')
        options.add_argument('--ignore-certificate-errors')
        options.add_argument('--disable-extensions')
        options.add_argument('--blink-settings=imagesEnabled=false')
        options.add_argument('--disable-blink-features=AutomationControlled')  # å…³é—­è‡ªåŠ¨åŒ–æ ‡è¯†
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.page_load_strategy = 'eager'  # å½“DOMå°±ç»ªæ—¶å°±å¼€å§‹æ“ä½œï¼Œä¸ç­‰å¾…å›¾ç‰‡ç­‰èµ„æº

        # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦ç¦ç”¨JavaScript
        if disable_javascript:
            logger.info("ç¦ç”¨JavaScriptæ¨¡å¼å·²å¯ç”¨ï¼ˆç”¨äºæ±‡ç‡æ•°æ®çˆ¬å–ï¼‰")
            options.add_experimental_option("prefs", {"profile.managed_default_content_settings.javascript": 2})

        # æ·»åŠ éšæœºç”¨æˆ·ä»£ç†
        user_agent = self.get_random_user_agent()
        options.add_argument(f'user-agent={user_agent}')
        logger.debug(f"ä½¿ç”¨ç”¨æˆ·ä»£ç†: {user_agent}")

        driver = None
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨Chrome
            from webdriver_manager.chrome import ChromeDriverManager

            driver_dir = ChromeDriverManager().install()
            # æ­£ç¡®çš„chromedriverè·¯å¾„åº”è¯¥æ˜¯ç›®å½•ä¸­çš„chromedriveræ–‡ä»¶
            driver_path = os.path.join(os.path.dirname(driver_dir), 'chromedriver')

            # ç¡®ä¿æ–‡ä»¶æœ‰æ‰§è¡Œæƒé™
            os.chmod(driver_path, 0o755)

            # driver_path = ChromeDriverManager().install()
            # driver_path ='/Users/dieselchen/.wdm/drivers/chromedriver/mac64/134.0.6998.165/chromedriver-mac-x64/chromedriver'
            # driver_path='/root/.wdm/drivers/chromedriver/linux64/140.0.7339.80/chromedriver-linux64/chromedriver'

            service = Service(executable_path=driver_path)

            # åˆ›å»ºdriverå¹¶ä¿®æ”¹navigator.webdriver
            driver = webdriver.Chrome(service=service, options=options)

            logger.info("æˆåŠŸåˆå§‹åŒ– Chrome WebDriver")
        except Exception as e:
            logger.warning(f"Chrome WebDriver åˆå§‹åŒ–å¤±è´¥: {str(e)}")

            try:
                # å°è¯•ä½¿ç”¨Edge
                from webdriver_manager.microsoft import EdgeChromiumDriverManager

                edge_options = webdriver.EdgeOptions()
                for arg in options.arguments:
                    edge_options.add_argument(arg)
                edge_options.use_chromium = True
                edge_options.page_load_strategy = 'eager'

                driver_path = EdgeChromiumDriverManager().install()

                # åˆ›å»ºä¸€ä¸ªç©ºçš„æ—¥å¿—æ–‡ä»¶å¯¹è±¡æ¥æŠ‘åˆ¶è¾“å‡º
                if system == "Windows":
                    null_output = open(os.devnull, 'w')
                    service = Service(executable_path=driver_path, log_output=null_output)
                else:
                    service = Service(executable_path=driver_path)

                driver = webdriver.Edge(service=service, options=edge_options)

                # æ‰§è¡ŒJavaScriptä¿®æ”¹webdriveræ ‡è¯†
                driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                    'source': '''
                        Object.defineProperty(navigator, 'webdriver', {
                            get: () => undefined
                        });
                        // ä¿®æ”¹è¯­è¨€æ ‡è¯†ä»¥å¢åŠ éšæœºæ€§
                        Object.defineProperty(navigator, 'languages', {
                            get: () => ['zh-CN', 'zh', 'en-US', 'en']
                        });
                    '''
                })

                logger.info("æˆåŠŸåˆå§‹åŒ– Edge WebDriver")
            except Exception as e:
                logger.warning(f"Edge WebDriver åˆå§‹åŒ–å¤±è´¥: {str(e)}")

                try:
                    # æœ€åå°è¯•Firefox
                    from webdriver_manager.firefox import GeckoDriverManager

                    firefox_options = webdriver.FirefoxOptions()
                    for arg in options.arguments:
                        if not arg.startswith('--disable-dev-shm-usage') and not arg.startswith('--no-sandbox'):
                            firefox_options.add_argument(arg)
                    firefox_options.page_load_strategy = 'eager'
                    firefox_options.add_argument('--log-level=3')  # ä»…æ˜¾ç¤ºè‡´å‘½é”™è¯¯

                    # Firefoxç‰¹æœ‰çš„æ€§èƒ½è®¾ç½®
                    firefox_profile = webdriver.FirefoxProfile()
                    firefox_profile.set_preference("dom.webdriver.enabled", False)
                    firefox_profile.set_preference('useAutomationExtension', False)
                    firefox_profile.set_preference("general.useragent.override", user_agent)
                    firefox_profile.update_preferences()
                    firefox_options.profile = firefox_profile

                    driver_path = GeckoDriverManager().install()

                    service = Service(executable_path=driver_path)
                    driver = webdriver.Firefox(service=service, options=firefox_options)
                    logger.info("æˆåŠŸåˆå§‹åŒ– Firefox WebDriver")
                except Exception as e:
                    logger.error(f"æ‰€æœ‰WebDriveråˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    raise

        return driver

    def get_driver(self, driver_type='default'):
        """
        è·å–WebDriverå®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆå§‹åŒ–

        Args:
            driver_type: WebDriverç±»å‹ï¼Œå¯é€‰å€¼ï¼š'default'(é»˜è®¤), 'exchange_rate'(æ±‡ç‡æ•°æ®), 'daily'(æ—¥é¢‘æ•°æ®), 'monthly'(æœˆåº¦æ•°æ®)

        Returns:
            WebDriverå®ä¾‹
        """
        if driver_type == 'exchange_rate':
            # è·å–ä¸“ç”¨äºæ±‡ç‡æ•°æ®çš„WebDriverå®ä¾‹ï¼ˆç¦ç”¨JavaScriptï¼‰
            with self._exchange_rate_driver_lock:
                if self._exchange_rate_driver is None:
                    self._exchange_rate_driver = self._init_driver(disable_javascript=True)
                return self._exchange_rate_driver
        elif driver_type == 'daily':
            # è·å–ä¸“ç”¨äºæ—¥é¢‘æ•°æ®çš„WebDriverå®ä¾‹
            with self._daily_driver_lock:
                if self._daily_driver is None:
                    self._daily_driver = self._init_driver(disable_javascript=False)
                return self._daily_driver
        elif driver_type == 'monthly':
            # è·å–ä¸“ç”¨äºæœˆåº¦æ•°æ®çš„WebDriverå®ä¾‹
            with self._monthly_driver_lock:
                if self._monthly_driver is None:
                    self._monthly_driver = self._init_driver(disable_javascript=False)
                return self._monthly_driver
        else:
            # è·å–æ™®é€šWebDriverå®ä¾‹ï¼ˆå¯ç”¨JavaScriptï¼‰
            with self._driver_lock:
                if self._driver is None:
                    self._driver = self._init_driver(disable_javascript=False)
                return self._driver

    def close_driver(self, driver_type='default'):
        """
        å…³é—­WebDriverå®ä¾‹

        Args:
            driver_type: WebDriverç±»å‹ï¼Œå¯é€‰å€¼ï¼š'default'(é»˜è®¤), 'exchange_rate'(æ±‡ç‡æ•°æ®), 'daily'(æ—¥é¢‘æ•°æ®), 'monthly'(æœˆåº¦æ•°æ®)
        """
        if driver_type == 'exchange_rate':
            # å…³é—­æ±‡ç‡æ•°æ®ä¸“ç”¨çš„WebDriverå®ä¾‹
            with self._exchange_rate_driver_lock:
                if self._exchange_rate_driver:
                    try:
                        self._exchange_rate_driver.quit()
                        logger.info("æ±‡ç‡æ•°æ®WebDriverå·²å…³é—­")
                    except Exception as e:
                        logger.warning(f"å…³é—­æ±‡ç‡æ•°æ®WebDriveræ—¶å‡ºé”™: {str(e)}")
                    finally:
                        self._exchange_rate_driver = None
        elif driver_type == 'daily':
            # å…³é—­æ—¥é¢‘æ•°æ®ä¸“ç”¨çš„WebDriverå®ä¾‹
            with self._daily_driver_lock:
                if self._daily_driver:
                    try:
                        self._daily_driver.quit()
                        logger.info("æ—¥é¢‘æ•°æ®WebDriverå·²å…³é—­")
                    except Exception as e:
                        logger.warning(f"å…³é—­æ—¥é¢‘æ•°æ®WebDriveræ—¶å‡ºé”™: {str(e)}")
                    finally:
                        self._daily_driver = None
        elif driver_type == 'monthly':
            # å…³é—­æœˆåº¦æ•°æ®ä¸“ç”¨çš„WebDriverå®ä¾‹
            with self._monthly_driver_lock:
                if self._monthly_driver:
                    try:
                        self._monthly_driver.quit()
                        logger.info("æœˆåº¦æ•°æ®WebDriverå·²å…³é—­")
                    except Exception as e:
                        logger.warning(f"å…³é—­æœˆåº¦æ•°æ®WebDriveræ—¶å‡ºé”™: {str(e)}")
                    finally:
                        self._monthly_driver = None
        else:
            # å…³é—­æ™®é€šWebDriverå®ä¾‹
            with self._driver_lock:
                if self._driver:
                    try:
                        self._driver.quit()
                        logger.info("æ™®é€šWebDriverå·²å…³é—­")
                    except Exception as e:
                        logger.warning(f"å…³é—­æ™®é€šWebDriveræ—¶å‡ºé”™: {str(e)}")
                    finally:
                        self._driver = None

    def get_random_user_agent(self):
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:93.0) Gecko/20100101 Firefox/93.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:93.0) Gecko/20100101 Firefox/93.0"
        ]
        return random.choice(user_agents)


    def format_exchange_rate_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%mæœˆ %d, %Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_stee_price_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y/%m/%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_shibor_rate_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_sofr_date(self, raw_date):
        # è·å–å½“å‰å¹´ä»½
        current_year = datetime.now().year
        # æ‹¼æ¥å¹´ä»½ã€æœˆä»½å’Œæ—¥æœŸ
        full_date_str = f"{current_year}/{raw_date}"

        try:
            # è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡
            dt = datetime.strptime(full_date_str, "%Y/%m/%d")
            # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
            if platform.system() == "Windows":
                return dt.strftime("%Y/%#m/%d")
            else:  # Linux/macOS
                return dt.strftime("%Y/%-m/%d")
        except ValueError:
            print(f"æ—¥æœŸè§£æå¤±è´¥ï¼Œè¾“å…¥çš„æ—¥æœŸ {raw_date} æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ã€‚")
            return None

    def format_ester_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%m/%d/%Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_jpy_rate_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%m-%d-%Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_lpr_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_us_interest_rate_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    @log_execution_time
    @retry_on_timeout
    def crawl_exchange_rate(self, url):
        """ä¼˜åŒ–åçš„æ±‡ç‡æ•°æ®çˆ¬å–æ–¹æ³•ï¼ˆå¸¦è¯¦ç»†è°ƒè¯•æ—¥å¿—ï¼‰"""
        # è·å–ä¸“ç”¨äºæ±‡ç‡æ•°æ®çš„WebDriverå®ä¾‹ï¼ˆç¦ç”¨JavaScriptï¼‰
        driver = self.get_driver(driver_type='exchange_rate')
        logger.info(f"å¼€å§‹çˆ¬å–æ±‡ç‡æ•°æ®ï¼š{url}")

        try:

            # è®¾ç½®è¶…æ—¶ç­–ç•¥
            driver.set_page_load_timeout(10)
            wait = WebDriverWait(driver, 10, poll_frequency=0.25)

            try:
                logger.debug("å°è¯•åŠ è½½é¡µé¢...")
                driver.get(url)
            except TimeoutException:
                logger.warning("é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå¼ºåˆ¶åœæ­¢")
                driver.execute_script("window.stop();")

            # è¡¨æ ¼å®šä½ç­–ç•¥ä¼˜åŒ–
            try:
                logger.debug("å®šä½æ•°æ®è¡¨æ ¼...")
                table = wait.until(EC.presence_of_element_located((
                    By.CSS_SELECTOR, 'table.freeze-column-w-1'
                )))
                logger.debug("è¡¨æ ¼å®šä½æˆåŠŸ")
            except TimeoutException as e:
                logger.error("âŒ è¡¨æ ¼å®šä½å¤±è´¥ï¼Œå¯èƒ½åŸå› ï¼š")
                logger.error("1. é¡µé¢ç»“æ„å·²å˜æ›´")
                logger.error("2. åçˆ¬æœºåˆ¶è§¦å‘")
                logger.error("3. ç½‘ç»œè¯·æ±‚è¢«æ‹¦æˆª")
                raise

            # æ•°æ®è¡Œè·å–ç­–ç•¥
            def _load_rows(driver):
                """å¸¦æ»šåŠ¨åŠ è½½çš„è¡Œè·å–å‡½æ•°"""
                last_height = driver.execute_script("return document.body.scrollHeight")
                for _ in range(3):  # æœ€å¤šæ»šåŠ¨3æ¬¡
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    new_height = driver.execute_script("return document.body.scrollHeight")
                    if new_height == last_height:
                        break
                    last_height = new_height

                rows = driver.find_elements(
                    By.CSS_SELECTOR,
                    "tr.historical-data-v2_price__atUfP:not(:empty)"
                )
                return rows if len(rows) > 5 else None  # è‡³å°‘éœ€è¦5è¡Œæ•°æ®

            try:
                logger.debug("å°è¯•è·å–æ•°æ®è¡Œ...")
                rows = wait.until(
                    lambda d: _load_rows(d) or (_load_rows(d) and False),
                    message="æ•°æ®è¡ŒåŠ è½½å¤±è´¥"
                )
            except TimeoutException:
                logger.error("æ•°æ®è¡ŒåŠ è½½è¶…æ—¶ï¼Œå¯èƒ½åŸå› ï¼š")
                logger.error("1. æ»šåŠ¨åŠ è½½æœªè§¦å‘")
                logger.error("2. åçˆ¬éªŒè¯æœªé€šè¿‡")
                return None

            # æ•°æ®è§£æä¼˜åŒ–
            results = []
            required_columns = {"æ”¶ç›˜", "å¼€ç›˜", "é«˜", "ä½"}
            for idx, row in enumerate(rows[:10]):  # é™åˆ¶å¤„ç†å‰100è¡Œ
                try:


                    # åŠ¨æ€å®šä½å…ƒç´ 
                    date_cell = row.find_element(By.CSS_SELECTOR, "td:first-child time")
                    cells = row.find_elements(By.CSS_SELECTOR, "td:not([style*='display:none'])")


                    # æ•°æ®æ ¡éªŒ
                    if len(cells) < 5:
                        logger.debug(f"è·³è¿‡ç¬¬ {idx} è¡Œï¼Œæ•°æ®åˆ—ä¸è¶³")
                        continue

                    # æ„å»ºæ•°æ®è®°å½•
                    record = {
                        "æ—¥æœŸ": self.format_exchange_rate_date(date_cell.text),
                        "æ”¶ç›˜": cells[1].text.strip(),
                        "å¼€ç›˜": cells[2].text.strip(),
                        "é«˜": cells[3].text.strip(),
                        "ä½": cells[4].text.strip()
                    }

                    if url == 'https://cn.investing.com/rates-bonds/u.s.-10-year-bond-yield-historical-data':
                        record["æ¶¨è·Œå¹…"] = cells[5].text.strip()
                    else:
                        record["æ¶¨è·Œå¹…"] = cells[6].text.strip()


                    results.append(record)

                except StaleElementReferenceException:
                    logger.debug(f"ç¬¬ {idx} è¡Œå…ƒç´ å¤±æ•ˆï¼Œé‡æ–°è·å–ä¸­...")
                    rows = driver.find_elements(
                        By.CSS_SELECTOR,
                        "tr.historical-data-v2_price__atUfP:not(:empty)"
                    )
                    continue
                except Exception as e:
                    logger.debug(f"ç¬¬ {idx} è¡Œè§£æå¼‚å¸¸ï¼š{str(e)}")
                    continue

            logger.debug(f"æˆåŠŸè§£æ {len(results)} æ¡æœ‰æ•ˆè®°å½•")
            return results

        except Exception as e:
            logger.error(f"çˆ¬å–è¿‡ç¨‹å¼‚å¸¸ï¼š{str(e)}")
            logger.debug(f"å¼‚å¸¸å †æ ˆï¼š", exc_info=True)
            return None


    def find_last_row(self, sheet):
        """
        æ”¹è¿›çš„æŸ¥æ‰¾æœ€åä¸€è¡Œæ–¹æ³•ï¼šé€†å‘æŸ¥æ‰¾ç¬¬ä¸€ä¸ªéç©ºè¡Œ
        """
        for row in reversed(range(1, sheet.max_row + 1)):
            if any(cell.value for cell in sheet[row]):
                return row
        return 1  # å¦‚æœå…¨ä¸ºç©ºï¼Œä»ç¬¬ä¸€è¡Œå¼€å§‹

    def write_monthly_data(self, worksheet, data, row):
        """
        å†™å…¥æœˆåº¦æ•°æ®åˆ°Excel

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            data: åŒ…å«æ•°æ®çš„å­—å…¸
            row: è¦å†™å…¥çš„è¡Œå·
        """
        # è·å–å·¥ä½œè¡¨åç§°
        sheet_name = worksheet.title

        # è·å–è¯¥å·¥ä½œè¡¨å¯¹åº”çš„åˆ—å®šä¹‰
        if sheet_name in config.COLUMN_DEFINITIONS:
            columns = config.COLUMN_DEFINITIONS[sheet_name]
        else:
            logger.warning(f"æœªæ‰¾åˆ° {sheet_name} çš„åˆ—å®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤åˆ—")
            columns = ['æ—¥æœŸ']

        # å†™å…¥æ•°æ®
        for col_idx, col_name in enumerate(columns, 1):
            value = data.get(col_name, '')
            cell = worksheet.cell(row=row, column=col_idx, value=value)
            if sheet_name == 'Import and Export' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'Money Supply' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'PPI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'CPI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'PMI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'New Bank Loan Addition' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'US Interest Rate' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            else:
                cell.alignment = Alignment(horizontal='right')

        logger.info(f"å·²åœ¨ {sheet_name} çš„ç¬¬ {row} è¡Œå†™å…¥æœˆåº¦æ•°æ®")

    def write_daily_data(self, worksheet, data, last_row, sheet_name):
        """
        å†™å…¥æ—¥é¢‘æ•°æ®åˆ°Excel

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            data: åŒ…å«æ•°æ®çš„åˆ—è¡¨ï¼ˆé€šå¸¸æœ‰å¤šè¡Œï¼‰
            last_row: æœ€åä¸€è¡Œçš„è¡Œå·
            sheet_name: å·¥ä½œè¡¨åç§°

        Returns:
            bool: æ˜¯å¦æ›´æ–°äº†æ•°æ®
        """
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if not data or len(data) < 1:
            logger.error(f"{sheet_name}: æ•°æ®ä¸è¶³ï¼Œæ— æ³•å†™å…¥")
            return False

        # è·å–æœ€æ–°æ•°æ®çš„æ—¥æœŸ
        new_date_str = data[0].get("æ—¥æœŸ", "")
        if not new_date_str:
            logger.error(f"{sheet_name}: æ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸå­—æ®µ")
            return False

        # è·å–æœ€åä¸€è¡Œçš„æ—¥æœŸå€¼
        last_date_value = worksheet.cell(row=last_row, column=1).value

        # è§£æç°æœ‰æ—¥æœŸå’Œæ–°æ—¥æœŸä¸ºdatetimeå¯¹è±¡ï¼Œç”¨äºæ¯”è¾ƒ
        new_date_obj = None
        last_date_obj = None

        # è§£ææ–°æ—¥æœŸä¸ºdatetimeå¯¹è±¡
        try:
            if '/' in new_date_str:
                year, month, day = map(int, new_date_str.split('/'))
                new_date_obj = datetime(year, month, day)
            elif '-' in new_date_str:
                year, month, day = map(int, new_date_str.split('-'))
                new_date_obj = datetime(year, month, day)
        except Exception as e:
            logger.warning(f"{sheet_name}: è§£ææ–°æ—¥æœŸ '{new_date_str}' å¤±è´¥: {str(e)}")


        # è§£æç°æœ‰æ—¥æœŸ
        if isinstance(last_date_value, datetime):
            last_date_obj = last_date_value
        else:
            try:
                if last_date_value:
                    if sheet_name == 'SOFR':
                        month, day, year = map(int, str(last_date_value).split('/'))
                        last_date_obj = datetime(year, month, day)
                    elif sheet_name == 'Shibor':
                        year, month, day = map(int, str(last_date_value).split('-'))
                        last_date_obj = datetime(year, month, day)
                    else:
                        year, month, day = map(int, str(last_date_value).split('/'))
                        last_date_obj = datetime(year, month, day)
            except Exception as e:
                logger.warning(
                    f"{sheet_name}: è§£ææœ€åä¸€è¡Œæ—¥æœŸ '{last_date_value}' å¤±è´¥: {str(e)}"
                    f"last_date_value çš„å€¼æ˜¯: {last_date_value}ï¼Œç±»å‹æ˜¯: {type(last_date_value)} "
                )

        if new_date_obj is None or last_date_obj is None:
            # è‹¥æœ‰æ—¥æœŸå¯¹è±¡ä¸º Noneï¼Œåˆ™è®°å½•è­¦å‘Šä¿¡æ¯
            logger.warning(
                f"{sheet_name}: æ—¥æœŸå¯¹è±¡æ¯”è¾ƒå¤±è´¥ï¼Œè¯·é‡è¯•åä¸è¡Œè”ç³»ç®¡ç†å‘˜ã€‚"
                f"last_date_value çš„å€¼æ˜¯: {last_date_value}ï¼Œç±»å‹æ˜¯: {type(last_date_value)} "
                f"new_date_str çš„å€¼æ˜¯: {new_date_str}ï¼Œç±»å‹æ˜¯: {type(new_date_str)}"
            )
        # è‹¥ä¸¤ä¸ªæ—¥æœŸå¯¹è±¡éƒ½ä¸ä¸º Noneï¼Œåˆ™æ¯”è¾ƒæ—¥æœŸ
        elif new_date_obj.date() == last_date_obj.date():
            # è‹¥æ—¥æœŸç›¸åŒï¼Œåˆ™è®°å½•è°ƒè¯•ä¿¡æ¯å¹¶è¿”å› False
            logger.debug(
                f"{sheet_name}: æ—¥æœŸå¯¹è±¡æ¯”è¾ƒç›¸åŒ ({new_date_obj.date()} == {last_date_obj.date()})ï¼Œæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°"
            )
            return False

        # åœ¨æ•°æ®åˆ—è¡¨ä¸­æŸ¥æ‰¾æœ€åä¸€è¡Œæ—¥æœŸçš„ä½ç½®
        last_date_index = -1

        # ä½¿ç”¨datetimeå¯¹è±¡æ¯”è¾ƒæŸ¥æ‰¾
        if last_date_obj:
            for i, item in enumerate(data):
                item_date_str = item.get("æ—¥æœŸ", "")
                try:
                    if '/' in item_date_str:
                        year, month, day = map(int, item_date_str.split('/'))
                        item_date = datetime(year, month, day)
                    elif '-' in item_date_str:
                        year, month, day = map(int, item_date_str.split('-'))
                        item_date = datetime(year, month, day)
                    else:
                        continue

                    if item_date.date() == last_date_obj.date():
                        logger.debug(f"{sheet_name}: æ‰¾åˆ°æœ€åä¸€è¡Œæ—¥æœŸ(å¯¹è±¡æ¯”è¾ƒ): {item_date} åœ¨ç´¢å¼• {i} å³å°†æ’å…¥{i}ä¸ªæ–°æ•°æ® åˆ·æ–°æœ€åä¸€è¡Œæ•°æ®")
                        last_date_index = i
                        break
                except Exception as e:
                    logger.debug(f"{sheet_name}: è§£ææ—¥æœŸ '{item_date_str}' å¤±è´¥: {str(e)}")
                    continue

        # å¦‚æœæ‰¾åˆ°äº†æœ€åä¸€è¡Œæ—¥æœŸ
        if last_date_index != -1:
            # ç”¨æ‰¾åˆ°çš„æ•°æ®è¦†ç›–æœ€åä¸€è¡Œ
            self.write_single_daily_row(worksheet, data[last_date_index], last_row, sheet_name)
            logger.debug(f"{sheet_name}: å·²æ›´æ–°ç¬¬ {last_row} è¡Œæ•°æ®")

            # å°†æœ€åä¸€è¡Œæ—¥æœŸä¹‹å‰çš„æ•°æ®å€’åºæ’å…¥
            for i in range(last_date_index - 1, -1, -1):
                # æ’å…¥æ–°è¡Œ
                target_row = last_row + (last_date_index - i)
                self.write_single_daily_row(worksheet, data[i], target_row, sheet_name)
                logger.debug(f"{sheet_name}: å·²åœ¨ç¬¬ {target_row} è¡Œæ’å…¥æ–°æ•°æ®")

            return True
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°æœ€åä¸€è¡Œæ—¥æœŸï¼Œè®°å½•æ—¥å¿—
            logger.warning(f"{sheet_name}: çˆ¬å–çš„æœ€æ–°æ•°æ®å¹¶æ²¡æœ‰åŒ¹é…ä¸Šç°æœ‰æ•°æ®ï¼Œæ— æ³•æ›´æ–°.ç°æœ‰æ•°æ®{data}ï¼Œæœ€åä¸€è¡Œæ—¥æœŸ{last_date_obj}")
            # è¿›ä¸€æ­¥å¤„ç†ï¼šè§†ä¸ºé•¿æœŸæœªæ›´æ–°ï¼Œå°†ç°æœ‰æ•°æ®å€’åºè¿½åŠ åˆ°Excel
            try:
                logger.warning(f"{sheet_name}: æœªæ‰¾åˆ°åŒ¹é…æ—¥æœŸï¼Œåˆ¤å®šä¸ºé•¿æœŸæœªæ›´æ–°ã€‚å°†å€’åºè¿½åŠ  {len(data)} æ¡æ•°æ®åˆ°Excel")
                # ä»æœ€æ—§åˆ°æœ€æ–°å†™å…¥ï¼šå› ä¸ºdata[0]é€šå¸¸æ˜¯æœ€æ–°ï¼Œå› æ­¤å€’åºéå†
                for idx in range(len(data) - 1, -1, -1):
                    target_row = last_row + (len(data) - idx)
                    self.write_single_daily_row(worksheet, data[idx], target_row, sheet_name)
                    logger.debug(f"{sheet_name}: å€’åºè¿½åŠ  â€”â€” å·²åœ¨ç¬¬ {target_row} è¡Œå†™å…¥ç´¢å¼• {idx} çš„æ•°æ®")
                return True
            except Exception as e:
                logger.error(f"{sheet_name}: å€’åºè¿½åŠ å†™å…¥å¤±è´¥: {str(e)}")
                return False

    def write_single_daily_row(self, worksheet, row_data, row_num, sheet_name):
        """
        å†™å…¥å•è¡Œæ—¥é¢‘æ•°æ®

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            row_data: å•è¡Œæ•°æ®å­—å…¸
            row_num: è¦å†™å…¥çš„è¡Œå·
            sheet_name: å·¥ä½œè¡¨åç§°
        """
        # è·å–è¯¥å·¥ä½œè¡¨å¯¹åº”çš„åˆ—å®šä¹‰
        if sheet_name in config.COLUMN_DEFINITIONS:
            columns = config.COLUMN_DEFINITIONS[sheet_name]
        elif sheet_name in config.CURRENCY_PAIRS:
            # æ±‡ç‡æ•°æ®ä½¿ç”¨é€šç”¨åˆ—å®šä¹‰
            if sheet_name == 'USD 10Y':
                columns = config.COLUMN_DEFINITIONS['USD 10Y']
            else:
                columns = config.COLUMN_DEFINITIONS['CURRENCY']
        else:
            logger.warning(f"æœªæ‰¾åˆ° {sheet_name} çš„åˆ—å®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤åˆ—")
            columns = ['æ—¥æœŸ']

        # å†™å…¥æ•°æ®
        for col_idx, col_name in enumerate(columns, 1):
            value = row_data.get(col_name, '')
            if sheet_name == 'Shibor' and col_idx == 1:
                value_dt = datetime.strptime(value, '%Y/%m/%d')
                if isinstance(value_dt, datetime):
                    value = value_dt.strftime('%Y-%m-%d')
            if sheet_name == 'SOFR' and col_idx == 1:
                value_dt = datetime.strptime(value, '%Y/%m/%d')
                if isinstance(value_dt, datetime):
                    value = value_dt.strftime('%m/%d/%Y')
                    # å»æ‰æœˆä»½å’Œæ—¥æœŸçš„å‰å¯¼é›¶
                    month, day, year = value.split('/')
                    month = month.lstrip('0') if month.startswith('0') and len(month) > 1 else month
                    day = day.lstrip('0') if day.startswith('0') and len(day) > 1 else day
                    value = f"{month}/{day}/{year}"
            cell = worksheet.cell(row=row_num, column=col_idx, value=value)
            if sheet_name == 'Shibor':
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'SOFR' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'SOFR' and col_idx == 2:
                cell.alignment = Alignment(horizontal='left')
            else:
                cell.alignment = Alignment(horizontal='right')

    def update_excel(self):
        """
        æ›´æ–°ç°æœ‰Excelæ–‡ä»¶ï¼Œè¿½åŠ æ•°æ®åˆ°å¯¹åº”sheetçš„æœ€åä¸€è¡Œï¼ˆå¹¶å‘æ‰§è¡Œç‰ˆæœ¬ï¼‰
        æ±‡ç‡æ•°æ®ã€æ—¥é¢‘æ•°æ®å’Œæœˆåº¦æ•°æ®åˆ†åˆ«ä½¿ç”¨ä¸åŒçš„WebDriverå®ä¾‹å¹¶è¡Œçˆ¬å–
        """
        stats = CrawlStats()  # åˆ›å»ºç»Ÿè®¡å¯¹è±¡

        try:
            results = {}

            # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
            total_tasks = len(config.CURRENCY_PAIRS) + len(config.DAILY_DATA_PAIRS) + len(config.MONTHLY_DATA_PAIRS)
            completed_tasks = 0

            # æ‰“å°ä»»åŠ¡æ€»è§ˆ
            logger.info("=" * 50)
            logger.info("ğŸš€ å¼€å§‹æ•°æ®çˆ¬å–ä»»åŠ¡ï¼ˆä¸‰çº¿ç¨‹å¹¶å‘æ‰§è¡Œæ¨¡å¼ï¼‰")
            logger.info("=" * 50)
            logger.info(f"ğŸ“Š æ±‡ç‡æ•°æ®: {len(config.CURRENCY_PAIRS)} é¡¹")
            logger.info(f"ğŸ“ˆ æ—¥é¢‘æ•°æ®: {len(config.DAILY_DATA_PAIRS)} é¡¹")
            logger.info(f"ğŸ“… æœˆåº¦æ•°æ®: {len(config.MONTHLY_DATA_PAIRS)} é¡¹")
            logger.info(f"ğŸ”„ æ€»ä»»åŠ¡æ•°: {total_tasks} é¡¹")
            logger.info("=" * 50)

            # åˆå§‹åŒ–ä¸‰ä¸ªWebDriverå®ä¾‹
            logger.info("âš™ï¸ åˆå§‹åŒ–ä¸‰ä¸ªWebDriverå®ä¾‹...")
            # WebDriverå®ä¾‹å°†é€šè¿‡get_driver()æ–¹æ³•æŒ‰éœ€åˆå§‹åŒ–

            # æ›´æ–°è¿›åº¦çš„è¾…åŠ©å‡½æ•°
            def update_progress(sheet_name, data_type, success=True, error_msg=None):
                nonlocal completed_tasks
                completed_tasks += 1
                progress = int(completed_tasks / total_tasks * 100)
                progress_bar = "â–ˆ" * (progress // 5) + "â–‘" * (20 - progress // 5)

                if success:
                    logger.info(f"âœ… [{progress:3d}%] |{progress_bar}| {sheet_name} ({data_type})")
                elif error_msg:
                    logger.error(f"âŒ [{progress:3d}%] |{progress_bar}| {sheet_name} ({data_type}): {error_msg}")
                else:
                    logger.warning(f"âš ï¸ [{progress:3d}%] |{progress_bar}| {sheet_name} ({data_type}): æ•°æ®ä¸ºç©º")

            # å®šä¹‰çˆ¬å–å‡½æ•°
            def crawl_exchange_rate_task(pair, url):
                try:
                    # ä½¿ç”¨ä¸“ç”¨äºæ±‡ç‡æ•°æ®çš„WebDriver
                    driver = self.get_driver(driver_type='exchange_rate')
                    data = self.crawl_exchange_rate(url)
                    if data:
                        with results_lock:
                            results[pair] = data
                        stats.add_success(pair)
                        update_progress(pair, "currency")
                        return True
                    else:
                        stats.add_failure(pair, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                        update_progress(pair, "currency", False)
                        return False
                except Exception as e:
                    stats.add_failure(pair, str(e))
                    update_progress(pair, "currency", False, str(e))
                    return False

            def crawl_daily_task(sheet_name, info):
                try:
                    # ä½¿ç”¨ä¸“ç”¨äºæ—¥é¢‘æ•°æ®çš„WebDriver
                    driver = self.get_driver(driver_type='daily')
                    crawler_method = getattr(self, info['crawler'])
                    data = crawler_method(info['url'])

                    if data:
                        with results_lock:
                            results[sheet_name] = data
                        stats.add_success(sheet_name)
                        update_progress(sheet_name, "daily")
                        return True
                    else:
                        stats.add_failure(sheet_name, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                        update_progress(sheet_name, "daily", False)
                        return False
                except Exception as e:
                    stats.add_failure(sheet_name, str(e))
                    update_progress(sheet_name, "daily", False, str(e))
                    return False

            def crawl_monthly_task(sheet_name, info):
                try:
                    # ä½¿ç”¨ä¸“ç”¨äºæœˆåº¦æ•°æ®çš„WebDriver
                    driver = self.get_driver(driver_type='monthly')
                    crawler_method = getattr(self, info['crawler'])
                    data = crawler_method(info['url'])

                    if data:
                        # å¯¹äºæœˆåº¦æ•°æ®ï¼Œåªä¿ç•™ç¬¬ä¸€è¡Œ
                        if isinstance(data, list) and len(data) > 0:
                            with results_lock:
                                results[sheet_name] = data[0]
                        else:
                            with results_lock:
                                results[sheet_name] = data
                        stats.add_success(sheet_name)
                        update_progress(sheet_name, "monthly")
                        return True
                    else:
                        stats.add_failure(sheet_name, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                        update_progress(sheet_name, "monthly", False)
                        return False
                except Exception as e:
                    stats.add_failure(sheet_name, str(e))
                    update_progress(sheet_name, "monthly", False, str(e))
                    return False

            # ä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤å…±äº«èµ„æº
            results_lock = threading.RLock()

            # åˆ›å»ºä¸‰ä¸ªçº¿ç¨‹æ± ï¼Œåˆ†åˆ«ç”¨äºæ±‡ç‡æ•°æ®ã€æ—¥é¢‘æ•°æ®å’Œæœˆåº¦æ•°æ®
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as exchange_rate_executor, \
                 concurrent.futures.ThreadPoolExecutor(max_workers=1) as daily_executor, \
                 concurrent.futures.ThreadPoolExecutor(max_workers=1) as monthly_executor:

                # 1. æäº¤æ±‡ç‡æ•°æ®çˆ¬å–ä»»åŠ¡
                logger.info("å¼€å§‹çˆ¬å–æ±‡ç‡æ•°æ®ï¼ˆå¹¶å‘æ‰§è¡Œï¼‰...")
                exchange_rate_futures = []
                for pair, url in config.CURRENCY_PAIRS.items():
                    future = exchange_rate_executor.submit(crawl_exchange_rate_task, pair, url)
                    exchange_rate_futures.append(future)

                # 2. æäº¤æ—¥é¢‘æ•°æ®çˆ¬å–ä»»åŠ¡
                logger.info("å¼€å§‹çˆ¬å–æ—¥é¢‘æ•°æ®ï¼ˆå¹¶å‘æ‰§è¡Œï¼‰...")
                daily_futures = []
                for sheet_name, info in config.DAILY_DATA_PAIRS.items():
                    future = daily_executor.submit(crawl_daily_task, sheet_name, info)
                    daily_futures.append(future)

                # 3. æäº¤æœˆåº¦æ•°æ®çˆ¬å–ä»»åŠ¡
                logger.info("å¼€å§‹çˆ¬å–æœˆåº¦æ•°æ®ï¼ˆå¹¶å‘æ‰§è¡Œï¼‰...")
                monthly_futures = []
                for sheet_name, info in config.MONTHLY_DATA_PAIRS.items():
                    future = monthly_executor.submit(crawl_monthly_task, sheet_name, info)
                    monthly_futures.append(future)

                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                logger.info("ç­‰å¾…æ‰€æœ‰çˆ¬å–ä»»åŠ¡å®Œæˆ...")
                concurrent.futures.wait(exchange_rate_futures + daily_futures + monthly_futures)

            # å…³é—­WebDriverå®ä¾‹
            logger.info("çˆ¬å–ä»»åŠ¡å®Œæˆï¼Œå…³é—­WebDriverå®ä¾‹...")
            self.close_driver(driver_type='exchange_rate')  # å…³é—­æ±‡ç‡æ•°æ®WebDriver
            self.close_driver(driver_type='daily')         # å…³é—­æ—¥é¢‘æ•°æ®WebDriver
            self.close_driver(driver_type='monthly')       # å…³é—­æœˆåº¦æ•°æ®WebDriver

            logger.info("=" * 50)
            logger.info("ğŸ æ•°æ®çˆ¬å–å®Œæˆï¼Œå‡†å¤‡æ›´æ–°Excelæ–‡ä»¶...")

            # 4. æ›´æ–°Excelæ–‡ä»¶
            logger.info("å¼€å§‹æ›´æ–°Excelæ–‡ä»¶...")
            excel_path = config.EXCEL_OUTPUT_PATH
            logger.info(f"ğŸ“‚ æ‰“å¼€Excelæ–‡ä»¶: {os.path.basename(excel_path)}")

            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
            if not os.path.exists(excel_path):
                raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}ã€‚è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨äºæ­£ç¡®çš„ä½ç½®ã€‚")

            # è·¨è¿›ç¨‹æ–‡ä»¶é”ï¼Œé˜²æ­¢å¹¶å‘è¯»å†™å¯¼è‡´æŸå
            lock_path = excel_path + ".lock"
            lock_fd = None
            try:
                lock_fd = open(lock_path, 'w')
                fcntl.flock(lock_fd, fcntl.LOCK_EX)
                logger.debug("å·²è·å–Excelæ–‡ä»¶é”")

                # å°è¯•åŠ è½½å·¥ä½œç°¿ï¼›è‹¥å¤±è´¥åˆ™ä¸ä¿®æ”¹åŸæ–‡ä»¶ï¼Œç›´æ¥è¿”å›å¤±è´¥
                try:
                    wb = load_workbook(excel_path)
                except Exception as e:
                    logger.error(f"æ— æ³•æ‰“å¼€Excelæ–‡ä»¶ï¼ˆå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„xlsxæˆ–è¢«å ç”¨ï¼‰ï¼š{str(e)}")
                    return False
            except Exception as le:
                logger.error(f"è·å–Excelæ–‡ä»¶é”å¤±è´¥: {str(le)}")
                return False

            updated_sheets = []  # è®°å½•å·²æ›´æ–°çš„å·¥ä½œè¡¨

            # æ›´æ–°å„ä¸ªsheet
            excel_updates = []
            for sheet_name, data in results.items():
                if not data:
                    stats.add_skipped(sheet_name, "æ•°æ®ä¸ºç©º")
                    continue

                if sheet_name not in wb.sheetnames:
                    stats.add_skipped(sheet_name, "å·¥ä½œè¡¨ä¸å­˜åœ¨")
                    logger.warning(f"âš ï¸ å·¥ä½œè¡¨ {sheet_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")
                    continue

                ws = wb[sheet_name]

                # æŸ¥æ‰¾æœ€åä¸€è¡Œæ•°æ®
                last_row = self.find_last_row(ws)


                # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹æ³•
                if sheet_name in config.MONTHLY_DATA_PAIRS:
                    # æœˆåº¦æ•°æ®å¤„ç†
                    new_date = data.get("æ—¥æœŸ", "")
                    if not new_date:
                        stats.add_skipped(sheet_name, "æ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸå­—æ®µ")
                        continue

                    # è·å–æœ€åä¸€è¡Œçš„æ—¥æœŸå€¼
                    last_date_value = ws.cell(row=last_row, column=1).value

                    # å¯¹Import and Exportè¿›è¡Œç‰¹æ®Šå¤„ç†
                    if sheet_name == 'Import and Export':
                        # æ£€æŸ¥æœ€åä¸€è¡Œçš„æ•°æ®æ˜¯å¦å®Œæ•´ï¼ˆæ²¡æœ‰"-"ï¼‰
                        last_row_complete = True
                        columns = config.COLUMN_DEFINITIONS[sheet_name]

                        # æ£€æŸ¥æœ€åä¸€è¡Œçš„æ¯ä¸ªå•å…ƒæ ¼ï¼ˆé™¤äº†æ—¥æœŸåˆ—ï¼‰
                        for col_idx, col_name in enumerate(columns, 1):
                            if col_name == 'æ—¥æœŸ':
                                continue

                            current_value = ws.cell(row=last_row, column=col_idx).value
                            if current_value == '-' or current_value == '':
                                last_row_complete = False
                                break

                        if not last_row_complete:
                            # å¦‚æœæœ€åä¸€è¡Œä¸å®Œæ•´ï¼Œç”¨æ–°æ•°æ®æ›´æ–°è¿™ä¸€è¡Œ
                            self.write_monthly_data(ws, data, last_row)
                            excel_updates.append(sheet_name)
                            updated_sheets.append(sheet_name)
                            logger.info(f"ğŸ“ æ›´æ–°ä¸å®Œæ•´è¡Œ {sheet_name}: {new_date}")
                        elif str(last_date_value) != str(new_date):
                            # å¦‚æœæœ€åä¸€è¡Œå®Œæ•´ä¸”æ—¥æœŸä¸åŒï¼Œå†™å…¥æ–°è¡Œ
                            self.write_monthly_data(ws, data, last_row + 1)
                            excel_updates.append(sheet_name)
                            updated_sheets.append(sheet_name)
                            logger.info(f"ğŸ“ æ·»åŠ æ–°è¡Œ {sheet_name}: {new_date}")
                        else:
                            logger.info(f"âœ“ {sheet_name} æ•°æ®å·²æ˜¯æœ€æ–°ä¸”å®Œæ•´")
                    else:
                        # å…¶ä»–æœˆåº¦æ•°æ®çš„å¸¸è§„å¤„ç†
                        if str(last_date_value) != str(new_date):
                            self.write_monthly_data(ws, data, last_row + 1)
                            excel_updates.append(sheet_name)
                            updated_sheets.append(sheet_name)
                            logger.info(f"ğŸ“ æ›´æ–° {sheet_name}: {new_date}")
                        else:
                            logger.info(f"âœ“ {sheet_name} æ•°æ®å·²æ˜¯æœ€æ–°")
                else:
                    # æ—¥é¢‘æ•°æ®å¤„ç†ï¼ˆåŒ…æ‹¬æ±‡ç‡æ•°æ®ï¼‰
                    update_result = self.write_daily_data(ws, data, last_row, sheet_name)
                    if update_result:
                        excel_updates.append(sheet_name)
                        updated_sheets.append(sheet_name)
                        logger.info(f"ğŸ“ æ›´æ–° {sheet_name}")

            # æ‰“å°ç»Ÿè®¡æ‘˜è¦å¹¶è·å–æ‘˜è¦æ–‡æœ¬
            logger.info("=" * 50)
            summary_text = stats.print_summary()

            # æ·»åŠ ä¸€ä¸ªç‰¹æ®Šçš„æ—¥å¿—æ¶ˆæ¯ï¼Œæ ‡è®°ä¸ºæ‘˜è¦ä¿¡æ¯ï¼ˆå‰ç«¯æ®æ­¤æ”¶é›†å¹¶åœ¨æ”¶åˆ° SHOW_SUMMARY æ—¶æ˜¾ç¤ºï¼‰
            try:
                logger.info("SUMMARY_START")
                for line in summary_text.splitlines():
                    if line.strip():
                        logger.info(line)
                logger.info("SUMMARY_END")
            except Exception:
                # å›é€€ï¼šç›´æ¥è¾“å‡ºæ–‡æœ¬
                logger.info(summary_text)

            # ä¿å­˜Excelæ–‡ä»¶
            if excel_updates:
                logger.info(f"ğŸ’¾ ä¿å­˜Excelæ–‡ä»¶: {os.path.basename(excel_path)}")
                try:
                    tmp_path = excel_path + ".tmp"
                    wb.save(tmp_path)
                    os.replace(tmp_path, excel_path)
                    logger.info(f"âœ… Excelæ–‡ä»¶ä¿å­˜æˆåŠŸï¼Œå·²æ›´æ–° {len(updated_sheets)} ä¸ªå·¥ä½œè¡¨")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                    return False
            else:
                logger.info("â„¹ï¸ æ‰€æœ‰å·¥ä½œè¡¨æ•°æ®å‡å·²æ˜¯æœ€æ–°ï¼ŒExcelæ–‡ä»¶æœªåšä¿®æ”¹")

            return results
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°Excelè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
            return False
        finally:
            # é‡Šæ”¾æ–‡ä»¶é”
            try:
                if lock_fd is not None:
                    fcntl.flock(lock_fd, fcntl.LOCK_UN)
                    lock_fd.close()
                    logger.debug("å·²é‡Šæ”¾Excelæ–‡ä»¶é”")
                    # æ˜¾å¼æ ‡è®°Excelå·²é‡Šæ”¾ï¼Œä¾›å‰ç«¯/åç«¯å®Œæˆåˆ¤å®š
                    logger.info("EXCEL_UNLOCKED")
            except Exception:
                pass

    @log_execution_time
    @retry_on_timeout
    def crawl_steel_price(self, url):
        """
        çˆ¬å–é’¢é“ä»·æ ¼æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver(driver_type='daily')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:

            driver.set_page_load_timeout(30)
            wait = WebDriverWait(driver, 20, poll_frequency=0.25)

            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait.until(EC.element_to_be_clickable((By.XPATH, '//span[text()="ç›¸å¯¹ä»·æ ¼æŒ‡æ•°èµ°åŠ¿å›¾"]'))).click()

            # ç­‰å¾…æ•°æ®å®Œå…¨åŠ è½½
            wait.until(EC.presence_of_element_located((By.XPATH, '//td[contains(text(),"/") and string-length(text())>8]')))

            # è·å–è¡¨æ ¼å¼•ç”¨
            table = driver.find_element(By.XPATH, '//table[contains(@class,"detailTab")]')

            # å•æ¬¡è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ® - ä¿®æ”¹ä¸ºè·å–å‰10è¡Œ
            rows = table.find_elements(By.XPATH, './/tbody/tr[position()<=10]')
            data = []

            for row in rows:
                try:
                    # å®æ—¶è·å–å½“å‰è¡Œå…ƒç´ 
                    cells = row.find_elements(By.XPATH, './/td[not(contains(@style,"none"))]')


                    # æ•°æ®æ ¡éªŒ
                    if len(cells) < 10:
                        logger.debug(f"Steel price: è·³è¿‡æ— æ•ˆè¡Œï¼Œåˆ—æ•°ï¼š{len(cells)}")
                        continue

                    # ç«‹å³æå–æ–‡æœ¬å†…å®¹
                    cell_texts = [cell.text for cell in cells]


                    # åŠ¨æ€æ˜ å°„å­—æ®µ
                    item = {
                        "æ—¥æœŸ": self.format_stee_price_date(cells[0].get_attribute('textContent').strip()),
                        "æœ¬æ—¥": cells[1].text.strip(),
                        "æ˜¨æ—¥": cells[2].text.strip(),
                        "æ—¥ç¯æ¯”": cells[3].text.strip(),
                        "ä¸Šå‘¨": cells[4].text.strip(),
                        "å‘¨ç¯æ¯”": cells[5].text.strip(),
                        "ä¸Šæœˆåº¦": cells[6].text.strip(),
                        "ä¸ä¸Šæœˆæ¯”": cells[7].text.strip(),
                        "å»å¹´åŒæœŸ": cells[8].text.strip(),
                        "ä¸å»å¹´æ¯”": cells[9].text.strip(),
                    }
                    data.append(item)

                except StaleElementReferenceException:
                    logger.debug("Steel price: æ£€æµ‹åˆ°å…ƒç´ è¿‡æœŸï¼Œé‡æ–°è·å–è¡¨æ ¼æ•°æ®...")
                    # é‡æ–°è·å–è¡¨æ ¼å’Œè¡Œ
                    table = driver.find_element(By.XPATH, '//table[contains(@class,"detailTab")]')
                    rows = table.find_elements(By.XPATH, './/tbody/tr[position()<=10]')
                    continue
                except Exception as e:
                    logger.debug(f"Steel price: ç¬¬ {idx} è¡Œè§£æå¼‚å¸¸ï¼š{str(e)}")
                    continue

            logger.debug(f"æˆåŠŸæŠ“å– Steel price æ•°æ®: {len(data)} æ¡è®°å½•")
            return data

        except TimeoutException:
            logger.error("Steel price: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Steel price: çˆ¬å–æ•°æ®å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_shibor_rate(self, url):
        """
        çˆ¬å–Shiboråˆ©ç‡æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver(driver_type='daily')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'shibor-tendays-show-data')))

            # åˆå§‹åŒ–ç»“æœæ•°ç»„
            result_list = []
            row_count = 0

            for row in table.find_elements(By.CSS_SELECTOR, "tr:has(td)"):
                if row_count >= 10:  # ä¿®æ”¹ä¸ºè·å–å‰10è¡Œæ•°æ®
                    break  # åªå–å‰10è¡Œæ•°æ®

                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) < 9:
                    continue

                # è§£ææ•°æ®
                current_record = {}
                current_record['æ—¥æœŸ'] = self.format_shibor_rate_date(cells[0].text.strip())
                terms = ['O/N', '1W', '2W', '1M', '3M', '6M', '9M', '1Y']

                for i, term in enumerate(terms):
                    current_record[term] = cells[i + 1].text.strip()

                result_list.append(current_record)
                row_count += 1

            logger.debug(f"æˆåŠŸæŠ“å– Shibor æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Shibor: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Shibor: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_lpr(self, url):
        """
        çˆ¬å–LPRæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver(driver_type='daily')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'lpr-ten-days-table')))

            # æå–å…³é”®æ•°æ®
            rows = table.find_elements(By.CSS_SELECTOR, "tr")
            # è·³è¿‡è¡¨å¤´è¡Œ
            data_rows = rows[3:]

            # åˆå§‹åŒ–ç»“æœæ•°ç»„
            result_list = []
            row_index = 0

            for row in data_rows:
                if row_index >= 10:  # ä¿®æ”¹ä¸ºè·å–å‰10è¡Œæ•°æ®
                    break

                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) < 3:
                    continue

                date = self.format_lpr_date(cells[0].text.strip())
                term_1y = cells[1].text.strip()
                term_5y = cells[2].text.strip()

                current_record = {
                    "æ—¥æœŸ": date,
                    "1Y": term_1y,
                    "5Y": term_5y,
                    "PBOC_(6M-1Y)": 4.35,
                    "rowPBOC_(>5Y)": 4.9
                }
                result_list.append(current_record)
                row_index += 1

            logger.debug(f"æˆåŠŸæŠ“å– LPR æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("LPR: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"LPR: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_sofr(self, url):
        """
        çˆ¬å–SOFRæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver(driver_type='daily')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'pr_id_1-table')))

            # è·å–æ‰€æœ‰æ•°æ®è¡Œ
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # ç¡®ä¿åˆ—æ•°è¶³å¤Ÿ
                if len(cells) < 7:
                    logger.debug(f"SOFR: æ£€æµ‹åˆ°ä¸å®Œæ•´è¡Œï¼Œå®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # æŒ‰é¡ºåºæå–å­—æ®µ
                record = {
                    "æ—¥æœŸ": self.format_sofr_date(cells[0].text.strip()),
                    "Rate Type": 'SOFR',
                    "RATE(%)": cells[1].text.strip(),
                    "1ST PERCENTILE(%)": cells[2].text.strip(),
                    "25TH PERCENTILE(%)": cells[3].text.strip(),
                    "75TH PERCENTILE(%)": cells[4].text.strip(),
                    "99TH PERCENTILE(%)": cells[5].text.strip(),
                    "VOLUME ($Billions)": cells[6].text.strip()
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– SOFR æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("SOFR: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"SOFR: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_ester(self, url):
        """
        çˆ¬å–ESTERæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver(driver_type='daily')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
            wait = WebDriverWait(driver, 15)

            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            tables = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "table.table-striped")))
            if not tables:
                logger.error("ESTER: æœªæ‰¾åˆ°ç›®æ ‡è¡¨æ ¼")
                return None

            table = tables[0]  # å–ç¬¬ä¸€ä¸ªè¡¨æ ¼

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            logger.debug(f"ESTER: æ‰¾åˆ°æ•°æ®è¡Œæ•°ï¼š{len(rows)}")

            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 2:
                    logger.debug(f"ESTER: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": self.format_ester_date(cells[0].get_attribute('textContent').strip()),
                    "value": cells[1].get_attribute('textContent').strip().replace(' %', '')
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– ESTER æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("ESTER: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"ESTER: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_jpy_rate(self, url):
        """
        çˆ¬å–JPYåˆ©ç‡æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver(driver_type='daily')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(10)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)

            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table[class='table ']")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 2:
                    logger.debug(f"JPY rate: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": self.format_jpy_rate_date(cells[0].get_attribute('textContent').strip()),
                    "value": cells[1].get_attribute('textContent').strip().replace(' %', '')
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– JPY rate æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("JPY rate: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"JPY rate: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_us_interest_rate(self, url):
        """
        çˆ¬å–ç¾å›½åˆ©ç‡æ•°æ®
        """
        driver = self.get_driver(driver_type='monthly')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(10)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 4:
                    logger.debug(f"US Interest Rate: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å‰å€¼": cells[1].text.strip(),
                    "ç°å€¼": cells[2].text.strip(),
                    "å‘å¸ƒæ—¥æœŸ": self.format_us_interest_rate_date(cells[3].text.strip()),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– US Interest Rate æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("US Interest Rate: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"US Interest Rate: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_import_export(self, url):
        """
        çˆ¬å–è¿›å‡ºå£è´¸æ˜“æ•°æ®
        """
        driver = self.get_driver(driver_type='monthly')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(10)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 11:
                    logger.debug(f"Import Export: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆå‡ºå£é¢é‡‘é¢": cells[1].text.strip(),
                    "å½“æœˆå‡ºå£é¢åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "å½“æœˆå‡ºå£é¢ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "å½“æœˆè¿›å£é¢é‡‘é¢": cells[4].text.strip(),
                    "å½“æœˆè¿›å£é¢åŒæ¯”å¢é•¿": cells[5].text.strip(),
                    "å½“æœˆè¿›å£é¢ç¯æ¯”å¢é•¿": cells[6].text.strip(),
                    "ç´¯è®¡å‡ºå£é¢é‡‘é¢": cells[7].text.strip(),
                    "ç´¯è®¡å‡ºå£é¢åŒæ¯”å¢é•¿": cells[8].text.strip(),
                    "ç´¯è®¡è¿›å£é¢é‡‘é¢": cells[9].text.strip(),
                    "ç´¯è®¡è¿›å£é¢åŒæ¯”å¢é•¿": cells[10].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– Import and Export æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Import Export: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Import Export: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_money_supply(self, url):
        """
        çˆ¬å–è´§å¸ä¾›åº”æ•°æ®
        """
        driver = self.get_driver(driver_type='monthly')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(10)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 10:
                    logger.debug(f"Money Supply: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "M2æ•°é‡": cells[1].text.strip(),
                    "M2åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "M2ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "M1æ•°é‡": cells[4].text.strip(),
                    "M1åŒæ¯”å¢é•¿": cells[5].text.strip(),
                    "M1ç¯æ¯”å¢é•¿": cells[6].text.strip(),
                    "M0æ•°é‡": cells[7].text.strip(),
                    "M0åŒæ¯”å¢é•¿": cells[8].text.strip(),
                    "M0ç¯æ¯”å¢é•¿": cells[9].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– Money Supply æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Money Supply: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Money Supply: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_ppi(self, url):
        """
        çˆ¬å–ppiæ•°æ®
        """
        driver = self.get_driver(driver_type='monthly')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(10)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 4:
                    logger.debug(f"PPI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆ": cells[1].text.strip(),
                    "å½“æœˆåŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "ç´¯è®¡": cells[3].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– PPI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("PPI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"PPI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_cpi(self, url):
        """
        çˆ¬å–cpiæ•°æ®
        """
        driver = self.get_driver(driver_type='monthly')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(10)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 13:
                    logger.debug(f"CPI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å…¨å›½å½“æœˆ": cells[1].text.strip(),
                    "å…¨å›½åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "å…¨å›½ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "å…¨å›½ç´¯è®¡": cells[4].text.strip(),
                    "åŸå¸‚å½“æœˆ": cells[5].text.strip(),
                    "åŸå¸‚åŒæ¯”å¢é•¿": cells[6].text.strip(),
                    "åŸå¸‚ç¯æ¯”å¢é•¿": cells[7].text.strip(),
                    "åŸå¸‚ç´¯è®¡": cells[8].text.strip(),
                    "å†œæ‘å½“æœˆ": cells[9].text.strip(),
                    "å†œæ‘åŒæ¯”å¢é•¿": cells[10].text.strip(),
                    "å†œæ‘ç¯æ¯”å¢é•¿": cells[11].text.strip(),
                    "å†œæ‘ç´¯è®¡": cells[12].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– CPI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("CPI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"CPI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_pmi(self, url):
        """
        çˆ¬å–pmiæ•°æ®
        """
        driver = self.get_driver(driver_type='monthly')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(10)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 5:
                    logger.debug(f"PMI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "åˆ¶é€ ä¸šæŒ‡æ•°": cells[1].text.strip(),
                    "åˆ¶é€ ä¸šåŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "éåˆ¶é€ ä¸šæŒ‡æ•°": cells[3].text.strip(),
                    "éåˆ¶é€ ä¸šåŒæ¯”å¢é•¿": cells[4].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– PMI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("PMI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"PMI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_new_bank_loan_addition(self, url):
        """
        çˆ¬å– ä¸­å›½ æ–°å¢ä¿¡è´·æ•°æ®
        """
        driver = self.get_driver(driver_type='monthly')
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(10)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 6:
                    logger.debug(f"New Bank Loan: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½• - ä¿®å¤å­—æ®µåç§°ï¼Œé¿å…é‡å¤çš„"åŒæ¯”å¢é•¿"
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆ": cells[1].text.strip(),
                    "åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "ç´¯è®¡": cells[4].text.strip(),
                    "ç´¯è®¡åŒæ¯”å¢é•¿": cells[5].text.strip(),  # ä¿®æ”¹ä¸º"ç´¯è®¡åŒæ¯”å¢é•¿"ä»¥åŒºåˆ†
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– New Bank Loan Addition æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("New Bank Loan: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"New Bank Loan: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

if __name__ == "__main__":
    def main():
        """ä¸»å‡½æ•°"""
        import argparse

        parser = argparse.ArgumentParser(description='å¸‚åœºæ•°æ®çˆ¬å–å·¥å…·')
        parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ—¥å¿—')
        args = parser.parse_args()

        # è®¾ç½®æ—¥å¿—çº§åˆ«
        setup_logging(debug=args.debug)

        if args.debug:
            logger.info("å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œå°†æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")
        else:
            logger.info("ä½¿ç”¨æ ‡å‡†æ—¥å¿—çº§åˆ«ã€‚ä½¿ç”¨ --debug å‚æ•°å¯æŸ¥çœ‹è¯¦ç»†æ—¥å¿—")

        print("==================================================")
        print("å¸‚åœºæ•°æ®çˆ¬å–å·¥å…·")
        print("==================================================")

        analyzer = MarketDataAnalyzer()

        try:
            logger.info("å¼€å§‹æ›´æ–°å¸‚åœºæ•°æ®...")
            analyzer.update_excel()
        except KeyboardInterrupt:
            logger.info("æ£€æµ‹åˆ°ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å…³é—­èµ„æº...")
        except Exception as e:
            logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
            analyzer.close_driver()
            analyzer.close_driver(driver_type='exchange_rate')  # å…³é—­æ±‡ç‡æ•°æ®WebDriver
            analyzer.close_driver(driver_type='daily')         # å…³é—­æ—¥é¢‘æ•°æ®WebDriver
            analyzer.close_driver(driver_type='monthly')       # å…³é—­æœˆåº¦æ•°æ®WebDriver


        print("\nç¨‹åºè¿è¡Œå®Œæˆ")

    main()
