import requests
import pandas as pd
import logging
from datetime import datetime
import config
from bs4 import BeautifulSoup
import time
import random
from openpyxl import load_workbook
from openpyxl.styles import Alignment

import platform
from datetime import datetime
import os
import sys

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.firefox import GeckoDriverManager
from webdriver_manager.microsoft import EdgeChromiumDriverManager
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, WebDriverException
from selenium.webdriver import ActionChains

import time
import concurrent.futures

# åœ¨è„šæœ¬å¼€å¤´å¯¼å…¥å¹¶é…ç½®è¿æ¥æ± 
from urllib3.poolmanager import PoolManager
import urllib3

# ç¦ç”¨æ‰€æœ‰urllib3è­¦å‘Š
urllib3.disable_warnings()

# å¢åŠ è¿æ¥æ± å¤§å°å’Œè¿æ¥æ•°
class CustomPoolManager(PoolManager):
    def __init__(self, **kwargs):
        kwargs.setdefault('num_pools', 200)
        kwargs.setdefault('maxsize', 200)
        super().__init__(**kwargs)

# æ›¿æ¢é»˜è®¤è¿æ¥æ± ç®¡ç†å™¨
urllib3.PoolManager = CustomPoolManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, config.LOG_LEVEL),
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# ç¦ç”¨ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('selenium').setLevel(logging.WARNING)
logging.getLogger('webdriver_manager').setLevel(logging.WARNING)

# åˆ›å»ºä¸€ä¸ªç»Ÿè®¡å¯¹è±¡æ¥è·Ÿè¸ªæˆåŠŸå’Œå¤±è´¥çš„çˆ¬å–
class CrawlStats:
    def __init__(self):
        self.success = []
        self.failed = []
        self.skipped = []

    def add_success(self, name):
        self.success.append(name)

    def add_failure(self, name, reason):
        self.failed.append((name, reason))

    def add_skipped(self, name, reason):
        self.skipped.append((name, reason))

    def print_summary(self):
        logger.info("\n===== çˆ¬å–ç»Ÿè®¡æ‘˜è¦ =====")

        # æˆåŠŸé¡¹
        if self.success:
            logger.info(f"æˆåŠŸ: {len(self.success)} é¡¹")
            # å°†æˆåŠŸé¡¹åˆ†ç»„æ˜¾ç¤ºï¼Œæ¯è¡Œæœ€å¤šæ˜¾ç¤º 4 ä¸ªé¡¹ç›®
            success_items = self.success[:]
            while success_items:
                group = success_items[:4]
                success_items = success_items[4:]
                logger.info(f"  {', '.join(group)}")

        # å¤±è´¥é¡¹
        if self.failed:
            logger.info(f"\nå¤±è´¥: {len(self.failed)} é¡¹")
            for name, reason in self.failed:
                logger.error(f"  {name}: {reason}")

        # è·³è¿‡é¡¹
        if self.skipped:
            logger.info(f"\nè·³è¿‡: {len(self.skipped)} é¡¹")
            for name, reason in self.skipped:
                logger.warning(f"  {name}: {reason}")

def log_execution_time(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time
        # åªåœ¨DEBUGçº§åˆ«è®°å½•æ‰§è¡Œæ—¶é—´ï¼Œæˆ–è€…åœ¨å¤±è´¥æ—¶è®°å½•
        if result is None:
            logger.warning(f"{func.__name__} æ‰§è¡Œå¤±è´¥ï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
        else:
            logger.debug(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {elapsed_time:.2f} ç§’")
        return result
    return wrapper

def retry_on_timeout(func):
    """é‡è¯•è£…é¥°å™¨ï¼Œç”¨äºå¤„ç†è¶…æ—¶æƒ…å†µ"""
    def wrapper(*args, **kwargs):
        max_retries = 3
        retry_count = 0
        while retry_count < max_retries:
            try:
                return func(*args, **kwargs)
            except TimeoutException:
                retry_count += 1
                logger.warning(f"{func.__name__} ç¬¬{retry_count}æ¬¡å°è¯•è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•...")
                if retry_count >= max_retries:
                    logger.error(f"{func.__name__} å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œæ”¾å¼ƒå°è¯•")
                    return None
                # æ¯æ¬¡é‡è¯•å¢åŠ ç­‰å¾…æ—¶é—´
                time.sleep(2 * retry_count)
            except Exception as e:
                logger.error(f"{func.__name__} å‘ç”Ÿéè¶…æ—¶é”™è¯¯: {str(e)}")
                return None
    return wrapper

class MarketDataAnalyzer:
    _driver = None
    _driver_lock = False  # ç®€å•é”ï¼Œé˜²æ­¢å¹¶å‘åˆå§‹åŒ–

    def __init__(self):
        print("åˆå§‹åŒ–å¸‚åœºæ•°æ®åˆ†æå™¨...")
        # é¢„å…ˆåˆå§‹åŒ–WebDriver
        self._init_driver()

    def _init_driver(self):
        """
        ä¼˜åŒ–çš„WebDriveråˆå§‹åŒ–æ–¹æ³•
        """
        print("åˆå§‹åŒ–WebDriver...")
        logger.info("å¼€å§‹åˆå§‹åŒ–WebDriver")

        import os  # ç¡®ä¿osæ¨¡å—åœ¨å‡½æ•°å†…å¯ç”¨
        system = platform.system()

        # é€šç”¨é€‰é¡¹
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--no-sandbox')
        options.add_argument('--log-level=3')  # ä»…æ˜¾ç¤ºè‡´å‘½é”™è¯¯
        options.add_argument('--start-maximized')
        options.add_argument('--ignore-certificate-errors')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-blink-features=AutomationControlled')  # å…³é—­è‡ªåŠ¨åŒ–æ ‡è¯†
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.page_load_strategy = 'eager'  # å½“DOMå°±ç»ªæ—¶å°±å¼€å§‹æ“ä½œï¼Œä¸ç­‰å¾…å›¾ç‰‡ç­‰èµ„æº

        # æ·»åŠ éšæœºç”¨æˆ·ä»£ç†
        user_agent = self.get_random_user_agent()
        options.add_argument(f'user-agent={user_agent}')
        logger.debug(f"ä½¿ç”¨ç”¨æˆ·ä»£ç†: {user_agent}")

        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨Chrome
            from webdriver_manager.chrome import ChromeDriverManager

            driver_path = ChromeDriverManager().install()
            service = Service(executable_path=driver_path)

            # åˆ›å»ºdriverå¹¶ä¿®æ”¹navigator.webdriver
            self.__class__._driver = webdriver.Chrome(service=service, options=options)

            # æ‰§è¡ŒJavaScriptä¿®æ”¹webdriveræ ‡è¯†
            self.__class__._driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                    // ä¿®æ”¹è¯­è¨€æ ‡è¯†ä»¥å¢åŠ éšæœºæ€§
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-CN', 'zh', 'en-US', 'en']
                    });
                    // ä¿®æ”¹ç¡¬ä»¶å¹¶å‘çº¿ç¨‹
                    Object.defineProperty(navigator, 'hardwareConcurrency', {
                        get: () => 8
                    });
                '''
            })

            logger.info("æˆåŠŸåˆå§‹åŒ– Chrome WebDriver")
        except Exception as e:
            logger.warning(f"Chrome WebDriver åˆå§‹åŒ–å¤±è´¥: {str(e)}")

            try:
                # å°è¯•ä½¿ç”¨Edge
                from webdriver_manager.microsoft import EdgeChromiumDriverManager

                edge_options = webdriver.EdgeOptions()
                for arg in options.arguments:
                    edge_options.add_argument(arg)
                edge_options.use_chromium = True
                edge_options.page_load_strategy = 'eager'

                driver_path = EdgeChromiumDriverManager().install()

                # åˆ›å»ºä¸€ä¸ªç©ºçš„æ—¥å¿—æ–‡ä»¶å¯¹è±¡æ¥æŠ‘åˆ¶è¾“å‡º
                if system == "Windows":
                    null_output = open(os.devnull, 'w')
                    service = Service(executable_path=driver_path, log_output=null_output)
                else:
                    service = Service(executable_path=driver_path)

                self.__class__._driver = webdriver.Edge(service=service, options=edge_options)

                # æ‰§è¡ŒJavaScriptä¿®æ”¹webdriveræ ‡è¯†
                self.__class__._driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                    'source': '''
                        Object.defineProperty(navigator, 'webdriver', {
                            get: () => undefined
                        });
                        // ä¿®æ”¹è¯­è¨€æ ‡è¯†ä»¥å¢åŠ éšæœºæ€§
                        Object.defineProperty(navigator, 'languages', {
                            get: () => ['zh-CN', 'zh', 'en-US', 'en']
                        });
                    '''
                })

                logger.info("æˆåŠŸåˆå§‹åŒ– Edge WebDriver")
            except Exception as e:
                logger.warning(f"Edge WebDriver åˆå§‹åŒ–å¤±è´¥: {str(e)}")

                try:
                    # æœ€åå°è¯•Firefox
                    from webdriver_manager.firefox import GeckoDriverManager

                    firefox_options = webdriver.FirefoxOptions()
                    for arg in options.arguments:
                        if not arg.startswith('--disable-dev-shm-usage') and not arg.startswith('--no-sandbox'):
                            firefox_options.add_argument(arg)
                    firefox_options.page_load_strategy = 'eager'
                    firefox_options.add_argument('--log-level=3')  # ä»…æ˜¾ç¤ºè‡´å‘½é”™è¯¯

                    # Firefoxç‰¹æœ‰çš„æ€§èƒ½è®¾ç½®
                    firefox_profile = webdriver.FirefoxProfile()
                    firefox_profile.set_preference("dom.webdriver.enabled", False)
                    firefox_profile.set_preference('useAutomationExtension', False)
                    firefox_profile.set_preference("general.useragent.override", user_agent)
                    firefox_profile.update_preferences()
                    firefox_options.profile = firefox_profile

                    driver_path = GeckoDriverManager().install()

                    service = Service(executable_path=driver_path)
                    self.__class__._driver = webdriver.Firefox(service=service, options=firefox_options)
                    logger.info("æˆåŠŸåˆå§‹åŒ– Firefox WebDriver")
                except Exception as e:
                    logger.error(f"æ‰€æœ‰WebDriveråˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    raise

    @classmethod
    def get_driver(cls):
        """
        è·å–WebDriverå®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆå§‹åŒ–
        """
        if cls._driver is None:
            instance = cls()

        # æ£€æŸ¥é©±åŠ¨æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
        try:
            if cls._driver is not None:
                cls._driver.current_url  # å°è¯•è®¿é—®å±æ€§ä»¥æ£€æŸ¥é©±åŠ¨æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
        except (WebDriverException, Exception) as e:
            logger.warning(f"WebDriverå·²å¤±æ•ˆï¼Œé‡æ–°åˆå§‹åŒ–: {str(e)}")
            cls._driver = None
            instance = cls()

        return cls._driver

    def close_driver(self):
        """
        å…³é—­WebDriverå®ä¾‹
        """
        if self.__class__._driver:
            try:
                self.__class__._driver.quit()
            except Exception as e:
                logger.warning(f"å…³é—­WebDriveræ—¶å‡ºé”™: {str(e)}")
            finally:
                self.__class__._driver = None

    def get_random_user_agent(self):
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:93.0) Gecko/20100101 Firefox/93.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:93.0) Gecko/20100101 Firefox/93.0"
        ]
        return random.choice(user_agents)

    def simulate_human_behavior(self, driver):
        """æ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸ºï¼Œå‡å°‘è¢«æ£€æµ‹ä¸ºæœºå™¨äººçš„å¯èƒ½æ€§"""
        try:
            # éšæœºç­‰å¾…
            time.sleep(random.uniform(1, 3))

            # éšæœºæ»šåŠ¨
            for _ in range(random.randint(2, 5)):
                scroll_amount = random.randint(300, 700)
                driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
                time.sleep(random.uniform(0.5, 1.5))

            # éšæœºç§»åŠ¨é¼ æ ‡(ä½¿ç”¨ActionChains)
            if random.random() > 0.5:  # 50%æ¦‚ç‡æ‰§è¡Œ
                action = ActionChains(driver)
                for _ in range(random.randint(1, 3)):
                    action.move_by_offset(random.randint(-100, 100), random.randint(-100, 100))
                    action.perform()
                    time.sleep(random.uniform(0.1, 0.5))

            logger.debug("å·²æ‰§è¡Œäººç±»è¡Œä¸ºæ¨¡æ‹Ÿ")
        except Exception as e:
            logger.warning(f"æ¨¡æ‹Ÿäººç±»è¡Œä¸ºæ—¶å‡ºé”™: {str(e)}")

    def handle_cloudflare(self, driver, timeout=30):
        """å¤„ç†Cloudflareé˜²æŠ¤é¡µé¢"""
        try:
            start_time = time.time()
            while time.time() - start_time < timeout:
                if "Just a moment..." in driver.title or "Checking your browser" in driver.page_source:
                    logger.info("æ£€æµ‹åˆ°CloudflareéªŒè¯ï¼Œç­‰å¾…é€šè¿‡...")
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´å¹¶æ¨¡æ‹Ÿå‡ æ¬¡æ»šåŠ¨
                    self.simulate_human_behavior(driver)
                    time.sleep(random.uniform(2, 3))
                else:
                    logger.info("CloudflareéªŒè¯å·²é€šè¿‡æˆ–ä¸å­˜åœ¨")
                    return True  # éªŒè¯é€šè¿‡æˆ–ä¸å­˜åœ¨éªŒè¯
            logger.warning("CloudflareéªŒè¯è¶…æ—¶")
            return False  # è¶…æ—¶ï¼ŒéªŒè¯å¤±è´¥
        except Exception as e:
            logger.error(f"å¤„ç†CloudflareéªŒè¯æ—¶å‡ºé”™: {str(e)}")
            return False

    def format_exchange_rate_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%mæœˆ %d, %Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_stee_price_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y/%m/%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_shibor_rate_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_sofr_date(self, raw_date):
        # è·å–å½“å‰å¹´ä»½
        current_year = datetime.now().year
        # æ‹¼æ¥å¹´ä»½ã€æœˆä»½å’Œæ—¥æœŸ
        full_date_str = f"{current_year}/{raw_date}"

        try:
            # è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡
            dt = datetime.strptime(full_date_str, "%Y/%m/%d")
            # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
            if platform.system() == "Windows":
                return dt.strftime("%Y/%#m/%d")
            else:  # Linux/macOS
                return dt.strftime("%Y/%-m/%d")
        except ValueError:
            print(f"æ—¥æœŸè§£æå¤±è´¥ï¼Œè¾“å…¥çš„æ—¥æœŸ {raw_date} æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ã€‚")
            return None

    def format_ester_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%m/%d/%Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_jpy_rate_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%m-%d-%Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_lpr_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_us_interest_rate_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    @log_execution_time
    @retry_on_timeout
    def crawl_exchange_rate(self, url):
        """ä¼˜åŒ–åçš„æ±‡ç‡æ•°æ®çˆ¬å–æ–¹æ³•ï¼ˆå¸¦è¯¦ç»†è°ƒè¯•æ—¥å¿—ï¼‰"""
        driver = self.get_driver()
        logger.info(f"ğŸŒ å¼€å§‹çˆ¬å–æ±‡ç‡æ•°æ®ï¼š{url}")

        try:
            # # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé˜²æ­¢è¯·æ±‚è¿‡äºè§„å¾‹
            # wait_time = random.uniform(2, 5)
            # logger.debug(f"ç­‰å¾… {wait_time:.2f} ç§’åå‘èµ·è¯·æ±‚...")
            # time.sleep(wait_time)

            # è®¾ç½®è¶…æ—¶ç­–ç•¥
            driver.set_page_load_timeout(20)
            driver.implicitly_wait(5)
            wait = WebDriverWait(driver, 25, poll_frequency=1)

            try:
                logger.debug("ğŸš¦ å°è¯•åŠ è½½é¡µé¢...")
                driver.get(url)
            except TimeoutException:
                logger.warning("â° é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå¼ºåˆ¶åœæ­¢")
                driver.execute_script("window.stop();")

            # æ£€æŸ¥å¹¶å¤„ç†Cloudflareé˜²æŠ¤
            if not self.handle_cloudflare(driver):
                logger.error("æ— æ³•é€šè¿‡CloudflareéªŒè¯")
                return None

            # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
            self.simulate_human_behavior(driver)

            # è°ƒè¯•ï¼šä¿å­˜é¡µé¢å¿«ç…§
            if logger.isEnabledFor(logging.DEBUG):
                with open("page_source.html", "w", encoding="utf-8") as f:
                    f.write(driver.page_source)
                driver.save_screenshot("debug_snapshot.png")

            # è¡¨æ ¼å®šä½ç­–ç•¥ä¼˜åŒ–
            try:
                logger.debug("ğŸ” å®šä½æ•°æ®è¡¨æ ¼...")
                table = wait.until(EC.presence_of_element_located((
                    By.XPATH, '//table[contains(@class, "freeze-column")]'
                )))
                logger.debug("âœ… è¡¨æ ¼å®šä½æˆåŠŸ")
            except TimeoutException as e:
                logger.error("âŒ è¡¨æ ¼å®šä½å¤±è´¥ï¼Œå¯èƒ½åŸå› ï¼š")
                logger.error("1. é¡µé¢ç»“æ„å·²å˜æ›´")
                logger.error("2. åçˆ¬æœºåˆ¶è§¦å‘")
                logger.error("3. ç½‘ç»œè¯·æ±‚è¢«æ‹¦æˆª")
                raise

            # æ•°æ®è¡Œè·å–ç­–ç•¥
            def _load_rows(driver):
                """å¸¦æ»šåŠ¨åŠ è½½çš„è¡Œè·å–å‡½æ•°"""
                last_height = driver.execute_script("return document.body.scrollHeight")
                for _ in range(3):  # æœ€å¤šæ»šåŠ¨3æ¬¡
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1.5)
                    new_height = driver.execute_script("return document.body.scrollHeight")
                    if new_height == last_height:
                        break
                    last_height = new_height

                rows = driver.find_elements(
                    By.CSS_SELECTOR,
                    "tr.historical-data-v2_price__atUfP:not(:empty)"
                )
                return rows if len(rows) > 5 else None  # è‡³å°‘éœ€è¦5è¡Œæ•°æ®

            try:
                logger.debug("ğŸ”„ å°è¯•è·å–æ•°æ®è¡Œ...")
                rows = wait.until(
                    lambda d: _load_rows(d) or (_load_rows(d) and False),
                    message="æ•°æ®è¡ŒåŠ è½½å¤±è´¥"
                )
                logger.info(f"ğŸ“Š è·å–åˆ° {len(rows)} è¡Œæœ‰æ•ˆæ•°æ®")
            except TimeoutException:
                logger.error("â° æ•°æ®è¡ŒåŠ è½½è¶…æ—¶ï¼Œå¯èƒ½åŸå› ï¼š")
                logger.error("1. æ»šåŠ¨åŠ è½½æœªè§¦å‘")
                logger.error("2. åçˆ¬éªŒè¯æœªé€šè¿‡")
                return None

            # æ•°æ®è§£æä¼˜åŒ–
            results = []
            required_columns = {"æ”¶ç›˜", "å¼€ç›˜", "é«˜", "ä½"}
            for idx, row in enumerate(rows[:100]):  # é™åˆ¶å¤„ç†å‰100è¡Œ
                try:
                    # å¯è§†åŒ–æ£€æŸ¥
                    if not row.is_displayed():
                        driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth'});", row)
                        time.sleep(0.3)

                    # åŠ¨æ€å®šä½å…ƒç´ 
                    date_cell = row.find_element(By.CSS_SELECTOR, "td:first-child time")
                    cells = row.find_elements(By.CSS_SELECTOR, "td:not([style*='display:none'])")

                    # æ•°æ®æ ¡éªŒ
                    if len(cells) < 5:
                        logger.debug(f"è·³è¿‡ç¬¬ {idx} è¡Œï¼Œæ•°æ®åˆ—ä¸è¶³")
                        continue

                    # æ„å»ºæ•°æ®è®°å½•
                    record = {
                        "æ—¥æœŸ": self.format_exchange_rate_date(date_cell.text),
                        "æ”¶ç›˜": cells[1].text.strip(),
                        "å¼€ç›˜": cells[2].text.strip(),
                        "é«˜": cells[3].text.strip(),
                        "ä½": cells[4].text.strip()
                    }

                    # åŠ¨æ€å¤„ç†æ¶¨è·Œå¹…
                    if len(cells) >= 7:
                        record["æ¶¨è·Œå¹…"] = cells[6].text.strip()
                    elif "æ¶¨è·Œå¹…" in required_columns:
                        logger.warning(f"ç¬¬ {idx} è¡Œç¼ºå°‘æ¶¨è·Œå¹…æ•°æ®")

                    results.append(record)

                except StaleElementReferenceException:
                    logger.debug(f"ç¬¬ {idx} è¡Œå…ƒç´ å¤±æ•ˆï¼Œé‡æ–°è·å–ä¸­...")
                    rows = driver.find_elements(
                        By.CSS_SELECTOR,
                        "tr.historical-data-v2_price__atUfP:not(:empty)"
                    )
                    continue
                except Exception as e:
                    logger.debug(f"ç¬¬ {idx} è¡Œè§£æå¼‚å¸¸ï¼š{str(e)}")
                    continue

            logger.info(f"âœ… æˆåŠŸè§£æ {results} æ¡æœ‰æ•ˆè®°å½•")
            return results

        except Exception as e:
            logger.error(f"âŒ çˆ¬å–è¿‡ç¨‹å¼‚å¸¸ï¼š{str(e)}")
            logger.debug(f"å¼‚å¸¸å †æ ˆï¼š", exc_info=True)
            return None
        finally:
            driver.quit()
            logger.debug("ğŸ›‘ æµè§ˆå™¨å®ä¾‹å·²å…³é—­")


    def find_last_row(self, sheet):
        """
        æ”¹è¿›çš„æŸ¥æ‰¾æœ€åä¸€è¡Œæ–¹æ³•ï¼šé€†å‘æŸ¥æ‰¾ç¬¬ä¸€ä¸ªéç©ºè¡Œ
        """
        for row in reversed(range(1, sheet.max_row + 1)):
            if any(cell.value for cell in sheet[row]):
                return row
        return 1  # å¦‚æœå…¨ä¸ºç©ºï¼Œä»ç¬¬ä¸€è¡Œå¼€å§‹

    def write_monthly_data(self, worksheet, data, row):
        """
        å†™å…¥æœˆåº¦æ•°æ®åˆ°Excel

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            data: åŒ…å«æ•°æ®çš„å­—å…¸
            row: è¦å†™å…¥çš„è¡Œå·
        """
        # è·å–å·¥ä½œè¡¨åç§°
        sheet_name = worksheet.title

        # è·å–è¯¥å·¥ä½œè¡¨å¯¹åº”çš„åˆ—å®šä¹‰
        if sheet_name in config.COLUMN_DEFINITIONS:
            columns = config.COLUMN_DEFINITIONS[sheet_name]
        else:
            logger.warning(f"æœªæ‰¾åˆ° {sheet_name} çš„åˆ—å®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤åˆ—")
            columns = ['æ—¥æœŸ']

        # å†™å…¥æ•°æ®
        for col_idx, col_name in enumerate(columns, 1):
            value = data.get(col_name, '')
            cell = worksheet.cell(row=row, column=col_idx, value=value)
            if sheet_name == 'Import and Export' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'Money Supply' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'PPI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'CPI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'PMI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'New Bank Loan Addition' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'US Interest Rate' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            else:
                cell.alignment = Alignment(horizontal='right')

        logger.info(f"å·²åœ¨ {sheet_name} çš„ç¬¬ {row} è¡Œå†™å…¥æœˆåº¦æ•°æ®")

    def write_daily_data(self, worksheet, data, last_row, sheet_name):
        """
        å†™å…¥æ—¥é¢‘æ•°æ®åˆ°Excel

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            data: åŒ…å«æ•°æ®çš„åˆ—è¡¨ï¼ˆé€šå¸¸æœ‰å¤šè¡Œï¼‰
            last_row: æœ€åä¸€è¡Œçš„è¡Œå·
            sheet_name: å·¥ä½œè¡¨åç§°

        Returns:
            bool: æ˜¯å¦æ›´æ–°äº†æ•°æ®
        """
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if not data or len(data) < 1:
            logger.error(f"{sheet_name}: æ•°æ®ä¸è¶³ï¼Œæ— æ³•å†™å…¥")
            return False

        # è·å–æœ€æ–°æ•°æ®çš„æ—¥æœŸ
        new_date_str = data[0].get("æ—¥æœŸ", "")
        if not new_date_str:
            logger.error(f"{sheet_name}: æ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸå­—æ®µ")
            return False

        # è·å–æœ€åä¸€è¡Œçš„æ—¥æœŸå€¼
        last_date_value = worksheet.cell(row=last_row, column=1).value

        # è§£æç°æœ‰æ—¥æœŸå’Œæ–°æ—¥æœŸä¸ºdatetimeå¯¹è±¡ï¼Œç”¨äºæ¯”è¾ƒ
        new_date_obj = None
        last_date_obj = None

        # è§£ææ–°æ—¥æœŸä¸ºdatetimeå¯¹è±¡
        try:
            if '/' in new_date_str:
                year, month, day = map(int, new_date_str.split('/'))
                new_date_obj = datetime(year, month, day)
            elif '-' in new_date_str:
                year, month, day = map(int, new_date_str.split('-'))
                new_date_obj = datetime(year, month, day)
        except Exception as e:
            logger.warning(f"{sheet_name}: è§£ææ–°æ—¥æœŸ '{new_date_str}' å¤±è´¥: {str(e)}")


        # è§£æç°æœ‰æ—¥æœŸ
        if isinstance(last_date_value, datetime):
            last_date_obj = last_date_value
        else:
            try:
                if last_date_value:
                    if sheet_name == 'SOFR':
                        month, day, year = map(int, str(last_date_value).split('/'))
                        last_date_obj = datetime(year, month, day)
                    elif sheet_name == 'Shibor':
                        year, month, day = map(int, str(last_date_value).split('-'))
                        last_date_obj = datetime(year, month, day)
                    else:
                        year, month, day = map(int, str(last_date_value).split('/'))
                        last_date_obj = datetime(year, month, day)
            except Exception as e:
                logger.warning(
                    f"{sheet_name}: è§£ææœ€åä¸€è¡Œæ—¥æœŸ '{last_date_value}' å¤±è´¥: {str(e)}"
                    f"last_date_value çš„å€¼æ˜¯: {last_date_value}ï¼Œç±»å‹æ˜¯: {type(last_date_value)} "
                )

        if new_date_obj is None or last_date_obj is None:
            # è‹¥æœ‰æ—¥æœŸå¯¹è±¡ä¸º Noneï¼Œåˆ™è®°å½•è­¦å‘Šä¿¡æ¯
            logger.warning(
                f"{sheet_name}: æ—¥æœŸå¯¹è±¡æ¯”è¾ƒå¤±è´¥ï¼Œè¯·é‡è¯•åä¸è¡Œè”ç³»ç®¡ç†å‘˜ã€‚"
                f"last_date_value çš„å€¼æ˜¯: {last_date_value}ï¼Œç±»å‹æ˜¯: {type(last_date_value)} "
                f"new_date_str çš„å€¼æ˜¯: {new_date_str}ï¼Œç±»å‹æ˜¯: {type(new_date_str)}"
            )
        # è‹¥ä¸¤ä¸ªæ—¥æœŸå¯¹è±¡éƒ½ä¸ä¸º Noneï¼Œåˆ™æ¯”è¾ƒæ—¥æœŸ
        elif new_date_obj.date() == last_date_obj.date():
            # è‹¥æ—¥æœŸç›¸åŒï¼Œåˆ™è®°å½•è°ƒè¯•ä¿¡æ¯å¹¶è¿”å› False
            logger.debug(
                f"{sheet_name}: æ—¥æœŸå¯¹è±¡æ¯”è¾ƒç›¸åŒ ({new_date_obj.date()} == {last_date_obj.date()})ï¼Œæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°"
            )
            return False

        # åœ¨æ•°æ®åˆ—è¡¨ä¸­æŸ¥æ‰¾æœ€åä¸€è¡Œæ—¥æœŸçš„ä½ç½®
        last_date_index = -1

        # ä½¿ç”¨datetimeå¯¹è±¡æ¯”è¾ƒæŸ¥æ‰¾
        if last_date_obj:
            for i, item in enumerate(data):
                item_date_str = item.get("æ—¥æœŸ", "")
                try:
                    if '/' in item_date_str:
                        year, month, day = map(int, item_date_str.split('/'))
                        item_date = datetime(year, month, day)
                    elif '-' in item_date_str:
                        year, month, day = map(int, item_date_str.split('-'))
                        item_date = datetime(year, month, day)
                    else:
                        continue

                    if item_date.date() == last_date_obj.date():
                        logger.debug(f"{sheet_name}: æ‰¾åˆ°æœ€åä¸€è¡Œæ—¥æœŸ(å¯¹è±¡æ¯”è¾ƒ): {item_date} åœ¨ç´¢å¼• {i} å³å°†æ’å…¥{i}ä¸ªæ–°æ•°æ® åˆ·æ–°æœ€åä¸€è¡Œæ•°æ®")
                        last_date_index = i
                        break
                except Exception as e:
                    logger.debug(f"{sheet_name}: è§£ææ—¥æœŸ '{item_date_str}' å¤±è´¥: {str(e)}")
                    continue

        # å¦‚æœæ‰¾åˆ°äº†æœ€åä¸€è¡Œæ—¥æœŸ
        if last_date_index != -1:
            # ç”¨æ‰¾åˆ°çš„æ•°æ®è¦†ç›–æœ€åä¸€è¡Œ
            self.write_single_daily_row(worksheet, data[last_date_index], last_row, sheet_name)
            logger.debug(f"{sheet_name}: å·²æ›´æ–°ç¬¬ {last_row} è¡Œæ•°æ®")

            # å°†æœ€åä¸€è¡Œæ—¥æœŸä¹‹å‰çš„æ•°æ®å€’åºæ’å…¥
            for i in range(last_date_index - 1, -1, -1):
                # æ’å…¥æ–°è¡Œ
                target_row = last_row + (last_date_index - i)
                self.write_single_daily_row(worksheet, data[i], target_row, sheet_name)
                logger.debug(f"{sheet_name}: å·²åœ¨ç¬¬ {target_row} è¡Œæ’å…¥æ–°æ•°æ®")

            return True
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°æœ€åä¸€è¡Œæ—¥æœŸï¼Œè®°å½•æ—¥å¿—
            logger.error(f"{sheet_name}: çˆ¬å–çš„æœ€æ–°æ•°æ®å¹¶æ²¡æœ‰åŒ¹é…ä¸Šç°æœ‰æ•°æ®ï¼Œæ— æ³•æ›´æ–°.ç°æœ‰æ•°æ®{data}ï¼Œæœ€åä¸€è¡Œæ—¥æœŸ{last_date_obj}")
            return False

    def write_single_daily_row(self, worksheet, row_data, row_num, sheet_name):
        """
        å†™å…¥å•è¡Œæ—¥é¢‘æ•°æ®

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            row_data: å•è¡Œæ•°æ®å­—å…¸
            row_num: è¦å†™å…¥çš„è¡Œå·
            sheet_name: å·¥ä½œè¡¨åç§°
        """
        # è·å–è¯¥å·¥ä½œè¡¨å¯¹åº”çš„åˆ—å®šä¹‰
        if sheet_name in config.COLUMN_DEFINITIONS:
            columns = config.COLUMN_DEFINITIONS[sheet_name]
        elif sheet_name in config.CURRENCY_PAIRS:
            # æ±‡ç‡æ•°æ®ä½¿ç”¨é€šç”¨åˆ—å®šä¹‰
            if sheet_name == 'USD 10Y':
                columns = config.COLUMN_DEFINITIONS['USD 10Y']
            else:
                columns = config.COLUMN_DEFINITIONS['CURRENCY']
        else:
            logger.warning(f"æœªæ‰¾åˆ° {sheet_name} çš„åˆ—å®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤åˆ—")
            columns = ['æ—¥æœŸ']

        # å†™å…¥æ•°æ®
        for col_idx, col_name in enumerate(columns, 1):
            value = row_data.get(col_name, '')
            if sheet_name == 'Shibor' and col_idx == 1:
                value_dt = datetime.strptime(value, '%Y/%m/%d')
                if isinstance(value_dt, datetime):
                    value = value_dt.strftime('%Y-%m-%d')
            if sheet_name == 'SOFR' and col_idx == 1:
                value_dt = datetime.strptime(value, '%Y/%m/%d')
                if isinstance(value_dt, datetime):
                    value = value_dt.strftime('%m/%d/%Y')
                    # å»æ‰æœˆä»½å’Œæ—¥æœŸçš„å‰å¯¼é›¶
                    month, day, year = value.split('/')
                    month = month.lstrip('0') if month.startswith('0') and len(month) > 1 else month
                    day = day.lstrip('0') if day.startswith('0') and len(day) > 1 else day
                    value = f"{month}/{day}/{year}"
            cell = worksheet.cell(row=row_num, column=col_idx, value=value)
            if sheet_name == 'Shibor':
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'SOFR' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'SOFR' and col_idx == 2:
                cell.alignment = Alignment(horizontal='left')
            else:
                cell.alignment = Alignment(horizontal='right')

    def update_excel(self):
        """
        æ›´æ–°ç°æœ‰Excelæ–‡ä»¶ï¼Œè¿½åŠ æ•°æ®åˆ°å¯¹åº”sheetçš„æœ€åä¸€è¡Œï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        MAX_RETRIES = 2  # æœ€å¤§é‡è¯•æ¬¡æ•°
        stats = CrawlStats()  # åˆ›å»ºç»Ÿè®¡å¯¹è±¡

        try:
            results = {}

            # 1. å¹¶è¡Œå¤„ç†æ±‡ç‡æ•°æ®ï¼ˆä¸éœ€è¦WebDriverï¼‰
            logger.info("å¼€å§‹å¹¶è¡Œçˆ¬å–æ±‡ç‡æ•°æ®...")
            with concurrent.futures.ThreadPoolExecutor(max_workers=7) as executor:
                future_to_sheet = {}

                for pair, url in config.CURRENCY_PAIRS.items():
                    logger.info(f"æ­£åœ¨åˆ†æ {pair} çš„æ•°æ®...")
                    future = executor.submit(self.crawl_exchange_rate, url)
                    future_to_sheet[future] = pair

                for future in concurrent.futures.as_completed(future_to_sheet):
                    sheet_name = future_to_sheet[future]
                    try:
                        data = future.result()
                        if data:
                            results[sheet_name] = data
                            stats.add_success(sheet_name)
                            logger.info(f"âœ“ æˆåŠŸè·å– {sheet_name} æ•°æ®")
                        else:
                            stats.add_failure(sheet_name, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                            logger.warning(f"{sheet_name}: çˆ¬å–è¿”å›ç©ºæ•°æ®")
                    except Exception as e:
                        stats.add_failure(sheet_name, str(e))
                        logger.error(f"{sheet_name}: å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")

            # 2. é¡ºåºå¤„ç†æ—¥é¢‘æ•°æ®ï¼ˆéœ€è¦WebDriverï¼‰
            logger.info("\nå¼€å§‹çˆ¬å–æ—¥é¢‘æ•°æ®...")
            for sheet_name, info in config.DAILY_DATA_PAIRS.items():
                logger.info(f"æ­£åœ¨åˆ†ææ—¥é¢‘æ•°æ® {sheet_name}...")
                try:
                    # ç¡®ä¿WebDriverå·²åˆå§‹åŒ–
                    self._init_driver()

                    # è°ƒç”¨å¯¹åº”çš„çˆ¬è™«æ–¹æ³•
                    crawler_method = getattr(self, info['crawler'])
                    data = crawler_method(info['url'])

                    if data:
                        results[sheet_name] = data
                        stats.add_success(sheet_name)
                        logger.info(f"âœ“ æˆåŠŸè·å– {sheet_name} æ•°æ®")
                    else:
                        stats.add_failure(sheet_name, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                        logger.warning(f"{sheet_name}: çˆ¬å–è¿”å›ç©ºæ•°æ®")
                except Exception as e:
                    stats.add_failure(sheet_name, str(e))
                    logger.error(f"{sheet_name}: å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")

            # 3. é¡ºåºå¤„ç†æœˆåº¦æ•°æ®ï¼ˆéœ€è¦WebDriverï¼‰
            logger.info("\nå¼€å§‹çˆ¬å–æœˆåº¦æ•°æ®...")
            for sheet_name, info in config.MONTHLY_DATA_PAIRS.items():
                logger.info(f"æ­£åœ¨åˆ†ææœˆåº¦æ•°æ® {sheet_name}...")
                try:
                    # ç¡®ä¿WebDriverå·²åˆå§‹åŒ–
                    self._init_driver()

                    # è°ƒç”¨å¯¹åº”çš„çˆ¬è™«æ–¹æ³•
                    crawler_method = getattr(self, info['crawler'])
                    data = crawler_method(info['url'])

                    if data:
                        # å¯¹äºæœˆåº¦æ•°æ®ï¼Œåªä¿ç•™ç¬¬ä¸€è¡Œ
                        if isinstance(data, list) and len(data) > 0:
                            results[sheet_name] = data[0]
                        else:
                            results[sheet_name] = data
                        stats.add_success(sheet_name)
                        logger.info(f"âœ“ æˆåŠŸè·å– {sheet_name} æ•°æ®")
                    else:
                        stats.add_failure(sheet_name, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                        logger.warning(f"{sheet_name}: çˆ¬å–è¿”å›ç©ºæ•°æ®")
                except Exception as e:
                    stats.add_failure(sheet_name, str(e))
                    logger.error(f"{sheet_name}: å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")

            # 4. æ›´æ–°Excelæ–‡ä»¶
            try:
                excel_path = config.EXCEL_OUTPUT_PATH
                logger.info(f"å°è¯•æ‰“å¼€Excelæ–‡ä»¶: {excel_path}")

                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
                if not os.path.exists(excel_path):
                    raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}ã€‚è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨äºæ­£ç¡®çš„ä½ç½®ã€‚")

                wb = load_workbook(excel_path)

                updated_sheets = []  # è®°å½•å·²æ›´æ–°çš„å·¥ä½œè¡¨

                # æ›´æ–°å„ä¸ªsheet
                excel_updates = []
                for sheet_name, data in results.items():
                    if not data:
                        stats.add_skipped(sheet_name, "æ•°æ®ä¸ºç©º")
                        logger.warning(f"å·¥ä½œè¡¨ {sheet_name} çš„æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡æ›´æ–°")
                        continue

                    if sheet_name not in wb.sheetnames:
                        stats.add_skipped(sheet_name, "å·¥ä½œè¡¨ä¸å­˜åœ¨")
                        logger.warning(f"å·¥ä½œè¡¨ {sheet_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")
                        continue

                    ws = wb[sheet_name]

                    # æŸ¥æ‰¾æœ€åä¸€è¡Œæ•°æ®
                    last_row = self.find_last_row(ws)


                    # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹æ³•
                    if sheet_name in config.MONTHLY_DATA_PAIRS:
                        # æœˆåº¦æ•°æ®å¤„ç†
                        new_date = data.get("æ—¥æœŸ", "")
                        if not new_date:
                            stats.add_skipped(sheet_name, "æ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸå­—æ®µ")
                            continue

                        # è·å–æœ€åä¸€è¡Œçš„æ—¥æœŸå€¼
                        last_date_value = ws.cell(row=last_row, column=1).value

                        # å¯¹Import and Exportè¿›è¡Œç‰¹æ®Šå¤„ç†
                        if sheet_name == 'Import and Export':
                            # å³ä½¿æ—¥æœŸç›¸åŒï¼Œä¹Ÿéœ€è¦æ£€æŸ¥æ•°æ®æ˜¯å¦ä»"-"æ›´æ–°ä¸ºå…·ä½“æ•°å€¼
                            need_update = False

                            # å¦‚æœæ—¥æœŸä¸åŒï¼Œç›´æ¥æ›´æ–°
                            if str(last_date_value) != str(new_date):
                                need_update = True
                            else:
                                # æ—¥æœŸç›¸åŒï¼Œæ£€æŸ¥å„åˆ—æ•°æ®æ˜¯å¦æœ‰ä»"-"æ›´æ–°ä¸ºå…·ä½“æ•°å€¼çš„æƒ…å†µ
                                columns = config.COLUMN_DEFINITIONS[sheet_name]
                                for col_idx, col_name in enumerate(columns, 1):
                                    if col_name == 'æ—¥æœŸ':
                                        continue

                                    # è·å–Excelä¸­çš„å½“å‰å€¼
                                    current_value = ws.cell(row=last_row, column=col_idx).value
                                    # è·å–æ–°æ•°æ®ä¸­çš„å€¼
                                    new_value = data.get(col_name, '')

                                    # æ£€æŸ¥æ˜¯å¦ä»"-"æ›´æ–°ä¸ºå…·ä½“æ•°å€¼
                                    if (current_value == '-' or current_value == '') and new_value != '-' and new_value != '':
                                        logger.info(f"{sheet_name}: åˆ— '{col_name}' ä» '{current_value}' æ›´æ–°ä¸º '{new_value}'")
                                        need_update = True
                                        break

                            if need_update:
                                self.write_monthly_data(ws, data, last_row)  # è¦†ç›–å½“å‰è¡Œ
                                excel_updates.append(sheet_name)
                                updated_sheets.append(sheet_name)
                                logger.info(f"å·²åœ¨å·¥ä½œè¡¨ {sheet_name} çš„ç¬¬ {last_row+1} è¡Œæ’å…¥æ–°æ•°æ®: {new_date}")
                            else:
                                logger.info(f"å·¥ä½œè¡¨ {sheet_name} çš„æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
                        else:
                            # å…¶ä»–æœˆåº¦æ•°æ®çš„å¸¸è§„å¤„ç†
                            if str(last_date_value) != str(new_date):
                                self.write_monthly_data(ws, data, last_row + 1)
                                excel_updates.append(sheet_name)
                                updated_sheets.append(sheet_name)
                                logger.info(f"å·²åœ¨å·¥ä½œè¡¨ {sheet_name} çš„ç¬¬ {last_row+1} è¡Œæ’å…¥æ–°æ•°æ®: {new_date}")
                            else:
                                logger.info(f"å·¥ä½œè¡¨ {sheet_name} çš„æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
                    else:
                        # æ—¥é¢‘æ•°æ®å¤„ç†ï¼ˆåŒ…æ‹¬æ±‡ç‡æ•°æ®ï¼‰
                        update_result = self.write_daily_data(ws, data, last_row, sheet_name)
                        if update_result:
                            excel_updates.append(sheet_name)
                            updated_sheets.append(sheet_name)
                            logger.info(f"å·²åœ¨å·¥ä½œè¡¨ {sheet_name} çš„ç¬¬ {last_row} è¡Œæ’å…¥æ–°æ•°æ®")

                # æ‰“å°ç»Ÿè®¡æ‘˜è¦
                stats.print_summary()

                # ä¿å­˜Excelæ–‡ä»¶
                if excel_updates:
                    logger.info(f"å¼€å§‹ä¿å­˜Excelæ–‡ä»¶: {excel_path}")
                    try:
                        wb.save(excel_path)
                        logger.info(f"âœ… Excelæ–‡ä»¶ä¿å­˜æˆåŠŸï¼Œå·²æ›´æ–°ä»¥ä¸‹å·¥ä½œè¡¨: {', '.join(updated_sheets)}")
                    except Exception as e:
                        logger.error(f"ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                        return False
                else:
                    logger.info("æ‰€æœ‰å·¥ä½œè¡¨æ•°æ®å‡å·²æ˜¯æœ€æ–°ï¼ŒExcelæ–‡ä»¶æœªåšä¿®æ”¹")



                return results
            except FileNotFoundError as e:
                logger.error(str(e))
                raise  # é‡æ–°æŠ›å‡ºé”™è¯¯ï¼Œä¸å°è¯•åˆ›å»ºæ–°æ–‡ä»¶
            except Exception as e:
                logger.error(f"æ›´æ–°Excelè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
                raise  # é‡æ–°æŠ›å‡ºé”™è¯¯
        finally:
            self.close_driver()

    @log_execution_time
    @retry_on_timeout
    def crawl_steel_price(self, url):
        """
        çˆ¬å–é’¢é“ä»·æ ¼æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")
        driver = self.get_driver()

        try:
            # é’ˆå¯¹ç‰¹å®šç«™ç‚¹å¢åŠ è¶…æ—¶æ—¶é—´
            if "mysteel.com" in url:  # Steel priceç«™ç‚¹
                driver.set_page_load_timeout(60)  # å¢åŠ åˆ°60ç§’
                wait = WebDriverWait(driver, 30)  # å¢åŠ ç­‰å¾…æ—¶é—´
            elif "euribor-rates.eu" in url:  # ESTERç«™ç‚¹
                driver.set_page_load_timeout(60)
                wait = WebDriverWait(driver, 30)
            else:
                driver.set_page_load_timeout(20)
                wait = WebDriverWait(driver, 10)

            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait.until(EC.element_to_be_clickable((By.XPATH, '//span[text()="ç›¸å¯¹ä»·æ ¼æŒ‡æ•°èµ°åŠ¿å›¾"]'))).click()

            # ç­‰å¾…æ•°æ®å®Œå…¨åŠ è½½
            wait.until(EC.presence_of_element_located((By.XPATH, '//td[contains(text(),"/") and string-length(text())>8]')))

            # è·å–è¡¨æ ¼å¼•ç”¨
            table = driver.find_element(By.XPATH, '//table[contains(@class,"detailTab")]')

            # å•æ¬¡è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ® - ä¿®æ”¹ä¸ºè·å–å‰10è¡Œ
            rows = table.find_elements(By.XPATH, './/tbody/tr[position()<=10]')
            data = []

            for row in rows:
                try:
                    # å®æ—¶è·å–å½“å‰è¡Œå…ƒç´ 
                    cells = row.find_elements(By.XPATH, './/td[not(contains(@style,"none"))]')

                    # è¿‡æ»¤æ— æ•ˆè¡Œ
                    if len(cells) < 10:
                        logger.debug(f"Steel price: è·³è¿‡æ— æ•ˆè¡Œï¼Œåˆ—æ•°ï¼š{len(cells)}")
                        continue

                    # ç«‹å³æå–æ–‡æœ¬å†…å®¹
                    cell_texts = [cell.text for cell in cells]


                    # åŠ¨æ€æ˜ å°„å­—æ®µ
                    item = {
                        "æ—¥æœŸ": self.format_stee_price_date(cells[0].get_attribute('textContent').strip()),
                        "æœ¬æ—¥": cells[1].get_attribute('textContent').strip(),
                        "æ˜¨æ—¥": cells[2].get_attribute('textContent').strip(),
                        "æ—¥ç¯æ¯”": cells[3].get_attribute('textContent').strip(),
                        "ä¸Šå‘¨": cells[4].get_attribute('textContent').strip(),
                        "å‘¨ç¯æ¯”": cells[5].get_attribute('textContent').strip(),
                        "ä¸Šæœˆåº¦": cells[6].get_attribute('textContent').strip(),
                        "ä¸ä¸Šæœˆæ¯”": cells[7].get_attribute('textContent').strip(),
                        "å»å¹´åŒæœŸ": cells[8].get_attribute('textContent').strip(),
                        "ä¸å»å¹´æ¯”": cells[9].get_attribute('textContent').strip(),
                    }
                    data.append(item)

                except StaleElementReferenceException:
                    logger.debug("Steel price: æ£€æµ‹åˆ°å…ƒç´ è¿‡æœŸï¼Œé‡æ–°è·å–è¡¨æ ¼æ•°æ®...")
                    # é‡æ–°è·å–è¡¨æ ¼å’Œè¡Œ
                    table = driver.find_element(By.XPATH, '//table[contains(@class,"detailTab")]')
                    rows = table.find_elements(By.XPATH, './/tbody/tr[position()<=10]')
                    continue

            logger.debug(f"æˆåŠŸæŠ“å– Steel price æ•°æ®: {len(data)} æ¡è®°å½•")
            return data

        except TimeoutException:
            logger.error("Steel price: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Steel price: çˆ¬å–æ•°æ®å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    def crawl_shibor_rate(self, url):
        """
        çˆ¬å–Shiboråˆ©ç‡æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'shibor-tendays-show-data')))

            # åˆå§‹åŒ–ç»“æœæ•°ç»„
            result_list = []
            row_count = 0

            for row in table.find_elements(By.CSS_SELECTOR, "tr:has(td)"):
                if row_count >= 10:  # ä¿®æ”¹ä¸ºè·å–å‰10è¡Œæ•°æ®
                    break  # åªå–å‰10è¡Œæ•°æ®

                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) < 9:
                    continue

                # è§£ææ•°æ®
                current_record = {}
                current_record['æ—¥æœŸ'] = self.format_shibor_rate_date(cells[0].text.strip())
                terms = ['O/N', '1W', '2W', '1M', '3M', '6M', '9M', '1Y']

                for i, term in enumerate(terms):
                    current_record[term] = cells[i + 1].text.strip()

                result_list.append(current_record)
                row_count += 1

            logger.debug(f"æˆåŠŸæŠ“å– Shibor æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Shibor: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Shibor: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    def crawl_lpr(self, url):
        """
        çˆ¬å–LPRæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'lpr-ten-days-table')))

            # æå–å…³é”®æ•°æ®
            rows = table.find_elements(By.CSS_SELECTOR, "tr")
            # è·³è¿‡è¡¨å¤´è¡Œ
            data_rows = rows[3:]

            # åˆå§‹åŒ–ç»“æœæ•°ç»„
            result_list = []
            row_index = 0

            for row in data_rows:
                if row_index >= 10:  # ä¿®æ”¹ä¸ºè·å–å‰10è¡Œæ•°æ®
                    break

                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) < 3:
                    continue

                date = self.format_lpr_date(cells[0].text.strip())
                term_1y = cells[1].text.strip()
                term_5y = cells[2].text.strip()

                current_record = {
                    "æ—¥æœŸ": date,
                    "1Y": term_1y,
                    "5Y": term_5y,
                    "PBOC_(6M-1Y)": 4.35,
                    "rowPBOC_(>5Y)": 4.9
                }
                result_list.append(current_record)
                row_index += 1

            logger.debug(f"æˆåŠŸæŠ“å– LPR æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("LPR: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"LPR: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    def crawl_sofr(self, url):
        """
        çˆ¬å–SOFRæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'pr_id_1-table')))

            # è·å–æ‰€æœ‰æ•°æ®è¡Œ
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # ç¡®ä¿åˆ—æ•°è¶³å¤Ÿ
                if len(cells) < 7:
                    logger.debug(f"SOFR: æ£€æµ‹åˆ°ä¸å®Œæ•´è¡Œï¼Œå®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # æŒ‰é¡ºåºæå–å­—æ®µ
                record = {
                    "æ—¥æœŸ": self.format_sofr_date(cells[0].text.strip()),
                    "Rate Type": 'SOFR',
                    "RATE(%)": cells[1].text.strip(),
                    "1ST PERCENTILE(%)": cells[2].text.strip(),
                    "25TH PERCENTILE(%)": cells[3].text.strip(),
                    "75TH PERCENTILE(%)": cells[4].text.strip(),
                    "99TH PERCENTILE(%)": cells[5].text.strip(),
                    "VOLUME ($Billions)": cells[6].text.strip()
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– SOFR æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("SOFR: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"SOFR: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    def crawl_ester(self, url):
        """
        çˆ¬å–ESTERæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
            wait = WebDriverWait(driver, 15)

            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            tables = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "table.table-striped")))
            if not tables:
                logger.error("ESTER: æœªæ‰¾åˆ°ç›®æ ‡è¡¨æ ¼")
                return None

            table = tables[0]  # å–ç¬¬ä¸€ä¸ªè¡¨æ ¼

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            logger.debug(f"ESTER: æ‰¾åˆ°æ•°æ®è¡Œæ•°ï¼š{len(rows)}")

            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 2:
                    logger.debug(f"ESTER: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": self.format_ester_date(cells[0].get_attribute('textContent').strip()),
                    "value": cells[1].get_attribute('textContent').strip().replace(' %', '')
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– ESTER æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("ESTER: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"ESTER: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    def crawl_jpy_rate(self, url):
        """
        çˆ¬å–JPYåˆ©ç‡æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 15)

            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table[class='table ']")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 2:
                    logger.debug(f"JPY rate: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": self.format_jpy_rate_date(cells[0].get_attribute('textContent').strip()),
                    "value": cells[1].get_attribute('textContent').strip().replace(' %', '')
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– JPY rate æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("JPY rate: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"JPY rate: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_us_interest_rate(self, url):
        """
        çˆ¬å–ç¾å›½åˆ©ç‡æ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 4:
                    logger.debug(f"US Interest Rate: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å‰å€¼": cells[1].text.strip(),
                    "ç°å€¼": cells[2].text.strip(),
                    "å‘å¸ƒæ—¥æœŸ": self.format_us_interest_rate_date(cells[3].text.strip()),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– US Interest Rate æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("US Interest Rate: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"US Interest Rate: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_import_export(self, url):
        """
        çˆ¬å–è¿›å‡ºå£è´¸æ˜“æ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 11:
                    logger.debug(f"Import Export: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆå‡ºå£é¢é‡‘é¢": cells[1].text.strip(),
                    "å½“æœˆå‡ºå£é¢åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "å½“æœˆå‡ºå£é¢ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "å½“æœˆè¿›å£é¢é‡‘é¢": cells[4].text.strip(),
                    "å½“æœˆè¿›å£é¢åŒæ¯”å¢é•¿": cells[5].text.strip(),
                    "å½“æœˆè¿›å£é¢ç¯æ¯”å¢é•¿": cells[6].text.strip(),
                    "ç´¯è®¡å‡ºå£é¢é‡‘é¢": cells[7].text.strip(),
                    "ç´¯è®¡å‡ºå£é¢åŒæ¯”å¢é•¿": cells[8].text.strip(),
                    "ç´¯è®¡è¿›å£é¢é‡‘é¢": cells[9].text.strip(),
                    "ç´¯è®¡è¿›å£é¢åŒæ¯”å¢é•¿": cells[10].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– Import and Export æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Import Export: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Import Export: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_money_supply(self, url):
        """
        çˆ¬å–è´§å¸ä¾›åº”æ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 10:
                    logger.debug(f"Money Supply: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "M2æ•°é‡": cells[1].text.strip(),
                    "M2åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "M2ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "M1æ•°é‡": cells[4].text.strip(),
                    "M1åŒæ¯”å¢é•¿": cells[5].text.strip(),
                    "M1ç¯æ¯”å¢é•¿": cells[6].text.strip(),
                    "M0æ•°é‡": cells[7].text.strip(),
                    "M0åŒæ¯”å¢é•¿": cells[8].text.strip(),
                    "M0ç¯æ¯”å¢é•¿": cells[9].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– Money Supply æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Money Supply: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Money Supply: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_ppi(self, url):
        """
        çˆ¬å–ppiæ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 4:
                    logger.debug(f"PPI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆ": cells[1].text.strip(),
                    "å½“æœˆåŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "ç´¯è®¡": cells[3].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– PPI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("PPI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"PPI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_cpi(self, url):
        """
        çˆ¬å–cpiæ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 13:
                    logger.debug(f"CPI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å…¨å›½å½“æœˆ": cells[1].text.strip(),
                    "å…¨å›½åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "å…¨å›½ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "å…¨å›½ç´¯è®¡": cells[4].text.strip(),
                    "åŸå¸‚å½“æœˆ": cells[5].text.strip(),
                    "åŸå¸‚åŒæ¯”å¢é•¿": cells[6].text.strip(),
                    "åŸå¸‚ç¯æ¯”å¢é•¿": cells[7].text.strip(),
                    "åŸå¸‚ç´¯è®¡": cells[8].text.strip(),
                    "å†œæ‘å½“æœˆ": cells[9].text.strip(),
                    "å†œæ‘åŒæ¯”å¢é•¿": cells[10].text.strip(),
                    "å†œæ‘ç¯æ¯”å¢é•¿": cells[11].text.strip(),
                    "å†œæ‘ç´¯è®¡": cells[12].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– CPI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("CPI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"CPI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_pmi(self, url):
        """
        çˆ¬å–pmiæ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 5:
                    logger.debug(f"PMI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "åˆ¶é€ ä¸šæŒ‡æ•°": cells[1].text.strip(),
                    "åˆ¶é€ ä¸šåŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "éåˆ¶é€ ä¸šæŒ‡æ•°": cells[3].text.strip(),
                    "éåˆ¶é€ ä¸šåŒæ¯”å¢é•¿": cells[4].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– PMI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("PMI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"PMI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_new_bank_loan_addition(self, url):
        """
        çˆ¬å– ä¸­å›½ æ–°å¢ä¿¡è´·æ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£å›ºå®šç­‰å¾…
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 6:
                    logger.debug(f"New Bank Loan: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½• - ä¿®å¤å­—æ®µåç§°ï¼Œé¿å…é‡å¤çš„"åŒæ¯”å¢é•¿"
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆ": cells[1].text.strip(),
                    "åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "ç´¯è®¡": cells[4].text.strip(),
                    "ç´¯è®¡åŒæ¯”å¢é•¿": cells[5].text.strip(),  # ä¿®æ”¹ä¸º"ç´¯è®¡åŒæ¯”å¢é•¿"ä»¥åŒºåˆ†
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– New Bank Loan Addition æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("New Bank Loan: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"New Bank Loan: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

if __name__ == "__main__":
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = MarketDataAnalyzer()
    print("=" * 50)
    print("å¸‚åœºæ•°æ®çˆ¬å–å·¥å…·")
    print("=" * 50)

    try:
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        if len(sys.argv) > 1 and sys.argv[1] == "--debug":
            logger.setLevel(logging.DEBUG)
            print("å·²å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œå°†æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")
        else:
            # é»˜è®¤ä½¿ç”¨INFOçº§åˆ«ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
            logger.setLevel(logging.INFO)
            print("ä½¿ç”¨æ ‡å‡†æ—¥å¿—çº§åˆ«ã€‚ä½¿ç”¨ --debug å‚æ•°å¯æŸ¥çœ‹è¯¦ç»†æ—¥å¿—")

        print("\nå¼€å§‹æ›´æ–°å¸‚åœºæ•°æ®...")
        results = analyzer.update_excel()

        if results:
            print("\nç¨‹åºè¿è¡Œå®Œæˆ")
        else:
            print("\nç¨‹åºè¿è¡Œå®Œæˆï¼Œä½†æœªèƒ½æˆåŠŸæ›´æ–°æ•°æ®")

    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"\nç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}", exc_info=True)
    finally:
        # ç¡®ä¿å…³é—­WebDriver
        try:
            analyzer.close_driver()
        except:
            pass