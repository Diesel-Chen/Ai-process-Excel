import requests
import pandas as pd
import logging
from datetime import datetime
import config
from bs4 import BeautifulSoup
import time
import random
from openpyxl import load_workbook
from openpyxl.styles import Alignment

import platform
from datetime import datetime
import os
import sys
import threading

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.firefox import GeckoDriverManager
from webdriver_manager.microsoft import EdgeChromiumDriverManager
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, WebDriverException
from selenium.webdriver import ActionChains

import time
import concurrent.futures
from functools import wraps

# åœ¨è„šæœ¬å¼€å¤´å¯¼å…¥å¹¶é…ç½®è¿æ¥æ± 
from urllib3.poolmanager import PoolManager
import urllib3

# ç¦ç”¨æ‰€æœ‰urllib3è­¦å‘Š
urllib3.disable_warnings()

# å¢åŠ è¿æ¥æ± å¤§å°å’Œè¿æ¥æ•°
class CustomPoolManager(PoolManager):
    def __init__(self, **kwargs):
        kwargs.setdefault('num_pools', 200)
        kwargs.setdefault('maxsize', 200)
        super().__init__(**kwargs)

# æ›¿æ¢é»˜è®¤è¿æ¥æ± ç®¡ç†å™¨
urllib3.PoolManager = CustomPoolManager

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ·»åŠ å½©è‰²æ—¥å¿—è¾“å‡º
class ColoredFormatter(logging.Formatter):
    """è‡ªå®šä¹‰å½©è‰²æ—¥å¿—æ ¼å¼åŒ–å™¨"""

    COLORS = {
        'DEBUG': '\033[94m',     # è“è‰²
        'INFO': '\033[92m',      # ç»¿è‰²
        'WARNING': '\033[93m',   # é»„è‰²
        'ERROR': '\033[91m',     # çº¢è‰²
        'CRITICAL': '\033[91m\033[1m',  # çº¢è‰²åŠ ç²—
        'RESET': '\033[0m'       # é‡ç½®é¢œè‰²
    }

    def format(self, record):
        log_message = super().format(record)
        level_name = record.levelname
        if level_name in self.COLORS:
            return f"{self.COLORS[level_name]}{log_message}{self.COLORS['RESET']}"
        return log_message

def setup_logging(debug=False):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    level = logging.DEBUG if debug else logging.INFO

    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.setLevel(level)

    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(level)

    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    if os.name == 'posix':  # åœ¨ç±»Unixç³»ç»Ÿä¸Šå¯ç”¨å½©è‰²è¾“å‡º
        formatter = ColoredFormatter('%(message)s')
    else:
        formatter = logging.Formatter('%(message)s')

    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # æ–‡ä»¶å¤„ç†å™¨ - è¯¦ç»†æ—¥å¿—ä¿å­˜åˆ°æ–‡ä»¶
    file_handler = logging.FileHandler('market_data_crawler.log')
    file_handler.setLevel(level)
    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)

def log_execution_time(func):
    """è®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´çš„è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time
        # åªåœ¨DEBUGçº§åˆ«è®°å½•æ‰§è¡Œæ—¶é—´ï¼Œæˆ–è€…åœ¨å¤±è´¥æ—¶è®°å½•
        if result is None:
            logger.warning(f"{func.__name__} æ‰§è¡Œå¤±è´¥ï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
        else:
            logger.debug(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {elapsed_time:.2f} ç§’")
        return result
    return wrapper

def format_error_message(error):
    """æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯ï¼Œæå–å…³é”®éƒ¨åˆ†"""
    error_str = str(error)

    # å¦‚æœæ˜¯Seleniumé”™è¯¯ï¼Œæå–ä¸»è¦ä¿¡æ¯
    if "Session info" in error_str:
        # æå–ä¸»è¦é”™è¯¯ä¿¡æ¯ï¼Œå»é™¤å †æ ˆè·Ÿè¸ª
        main_error = error_str.split('Stacktrace:')[0].strip()
        return main_error

    # å¯¹äºå…¶ä»–é”™è¯¯ï¼Œç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯
    return error_str

def log_error(message, error=None, show_traceback=False):
    """ç»Ÿä¸€çš„é”™è¯¯æ—¥å¿—è®°å½•å‡½æ•°"""
    if error:
        error_msg = format_error_message(error)
        logger.error(f"{message}: {error_msg}")
        # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹è®°å½•å®Œæ•´å †æ ˆ
        if show_traceback:
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:", exc_info=True)
    else:
        logger.error(message)

def retry_on_timeout(func):
    """é‡è¯•è£…é¥°å™¨ï¼Œç”¨äºå¤„ç†è¶…æ—¶æƒ…å†µ"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        max_retries = 3
        retry_count = 0
        while retry_count < max_retries:
            try:
                return func(*args, **kwargs)
            except TimeoutException:
                retry_count += 1
                logger.warning(f"{func.__name__} ç¬¬{retry_count}æ¬¡å°è¯•è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•...")
                if retry_count >= max_retries:
                    logger.error(f"{func.__name__} å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œæ”¾å¼ƒå°è¯•")
                    return None
                # æ¯æ¬¡é‡è¯•å¢åŠ ç­‰å¾…æ—¶é—´
                time.sleep(2 * retry_count)
            except Exception as e:
                log_error(f"{func.__name__} å‘ç”Ÿé”™è¯¯", e, show_traceback=False)
                return None
    return wrapper

# ç¦ç”¨ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('selenium').setLevel(logging.WARNING)
logging.getLogger('webdriver_manager').setLevel(logging.WARNING)

# åˆ›å»ºä¸€ä¸ªç»Ÿè®¡å¯¹è±¡æ¥è·Ÿè¸ªæˆåŠŸå’Œå¤±è´¥çš„çˆ¬å–
class CrawlStats:
    """çˆ¬å–ç»Ÿè®¡ä¿¡æ¯ç±»ï¼Œç”¨äºè®°å½•çˆ¬å–æˆåŠŸã€å¤±è´¥å’Œè·³è¿‡çš„æ•°æ®"""

    def __init__(self):
        self.success = []
        self.failure = {}
        self.skipped = {}

    def add_success(self, name):
        self.success.append(name)

    def add_failure(self, name, reason):
        self.failure[name] = reason

    def add_skipped(self, name, reason):
        self.skipped[name] = reason

    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        logger.info("ğŸ“Š çˆ¬å–ç»Ÿè®¡æ‘˜è¦")
        logger.info("=" * 50)

        # æˆåŠŸæ•°æ®
        if self.success:
            logger.info(f"âœ… æˆåŠŸ: {len(self.success)} é¡¹")
            # æ¯è¡Œæœ€å¤šæ˜¾ç¤º4ä¸ªé¡¹ç›®
            for i in range(0, len(self.success), 4):
                chunk = self.success[i:i+4]
                logger.info(f"   {', '.join(chunk)}")

        # å¤±è´¥æ•°æ®
        if self.failure:
            logger.info(f"\nâŒ å¤±è´¥: {len(self.failure)} é¡¹")
            for name, reason in self.failure.items():
                logger.error(f"   {name}: {reason}")

        # è·³è¿‡æ•°æ®
        if self.skipped:
            logger.info(f"\nâ­ï¸ è·³è¿‡: {len(self.skipped)} é¡¹")
            for name, reason in self.skipped.items():
                logger.warning(f"   {name}: {reason}")

        logger.info("=" * 50)

class MarketDataAnalyzer:
    _driver = None
    _driver_lock = False  # ç®€å•é”ï¼Œé˜²æ­¢å¹¶å‘åˆå§‹åŒ–
    _driver_pool = {}  # ç”¨äºå­˜å‚¨çº¿ç¨‹IDåˆ°WebDriverå®ä¾‹çš„æ˜ å°„
    _driver_pool_lock = threading.RLock()  # ç”¨äºä¿æŠ¤driver_poolçš„çº¿ç¨‹å®‰å…¨é”

    def __init__(self):
        print("åˆå§‹åŒ–å¸‚åœºæ•°æ®åˆ†æå™¨...")
        # ä¸å†é¢„å…ˆåˆå§‹åŒ–WebDriverï¼Œè€Œæ˜¯åœ¨éœ€è¦æ—¶æŒ‰éœ€åˆ›å»º

    def _init_driver(self, thread_id=None):
        """
        ä¼˜åŒ–çš„WebDriveråˆå§‹åŒ–æ–¹æ³•ï¼Œæ”¯æŒä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„WebDriverå®ä¾‹

        Args:
            thread_id: å¯é€‰çš„çº¿ç¨‹IDï¼Œç”¨äºåœ¨driver_poolä¸­æ ‡è¯†è¯¥WebDriverå®ä¾‹

        Returns:
            WebDriverå®ä¾‹
        """
        if thread_id is None:
            thread_id = threading.get_ident()

        print(f"ä¸ºçº¿ç¨‹ {thread_id} åˆå§‹åŒ–WebDriver...")
        logger.info(f"ä¸ºçº¿ç¨‹ {thread_id} å¼€å§‹åˆå§‹åŒ–WebDriver")

        import os  # ç¡®ä¿osæ¨¡å—åœ¨å‡½æ•°å†…å¯ç”¨
        system = platform.system()

        # é€šç”¨é€‰é¡¹
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--no-sandbox')
        options.add_argument('--log-level=3')  # ä»…æ˜¾ç¤ºè‡´å‘½é”™è¯¯
        options.add_argument('--start-maximized')
        options.add_argument('--ignore-certificate-errors')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-blink-features=AutomationControlled')  # å…³é—­è‡ªåŠ¨åŒ–æ ‡è¯†
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.page_load_strategy = 'eager'  # å½“DOMå°±ç»ªæ—¶å°±å¼€å§‹æ“ä½œï¼Œä¸ç­‰å¾…å›¾ç‰‡ç­‰èµ„æº

        # æ·»åŠ éšæœºç”¨æˆ·ä»£ç†
        user_agent = self.get_random_user_agent()
        options.add_argument(f'user-agent={user_agent}')
        logger.debug(f"ä½¿ç”¨ç”¨æˆ·ä»£ç†: {user_agent}")

        driver = None
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨Chrome
            from webdriver_manager.chrome import ChromeDriverManager

            driver_path = ChromeDriverManager().install()
            # driver_path='/root/.wdm/drivers/chromedriver/linux64/134.0.6998.165/chromedriver-linux64/chromedriver'

            service = Service(executable_path=driver_path)

            # åˆ›å»ºdriverå¹¶ä¿®æ”¹navigator.webdriver
            driver = webdriver.Chrome(service=service, options=options)

            # æ‰§è¡ŒJavaScriptä¿®æ”¹webdriveræ ‡è¯†
            driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                    // ä¿®æ”¹è¯­è¨€æ ‡è¯†ä»¥å¢åŠ éšæœºæ€§
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-CN', 'zh', 'en-US', 'en']
                    });
                    // ä¿®æ”¹ç¡¬ä»¶å¹¶å‘çº¿ç¨‹
                    Object.defineProperty(navigator, 'hardwareConcurrency', {
                        get: () => 8
                    });
                '''
            })

            logger.info(f"çº¿ç¨‹ {thread_id} æˆåŠŸåˆå§‹åŒ– Chrome WebDriver")
        except Exception as e:
            logger.warning(f"çº¿ç¨‹ {thread_id} Chrome WebDriver åˆå§‹åŒ–å¤±è´¥: {str(e)}")

            try:
                # å°è¯•ä½¿ç”¨Edge
                from webdriver_manager.microsoft import EdgeChromiumDriverManager

                edge_options = webdriver.EdgeOptions()
                for arg in options.arguments:
                    edge_options.add_argument(arg)
                edge_options.use_chromium = True
                edge_options.page_load_strategy = 'eager'

                driver_path = EdgeChromiumDriverManager().install()

                # åˆ›å»ºä¸€ä¸ªç©ºçš„æ—¥å¿—æ–‡ä»¶å¯¹è±¡æ¥æŠ‘åˆ¶è¾“å‡º
                if system == "Windows":
                    null_output = open(os.devnull, 'w')
                    service = Service(executable_path=driver_path, log_output=null_output)
                else:
                    service = Service(executable_path=driver_path)

                driver = webdriver.Edge(service=service, options=edge_options)

                # æ‰§è¡ŒJavaScriptä¿®æ”¹webdriveræ ‡è¯†
                driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                    'source': '''
                        Object.defineProperty(navigator, 'webdriver', {
                            get: () => undefined
                        });
                        // ä¿®æ”¹è¯­è¨€æ ‡è¯†ä»¥å¢åŠ éšæœºæ€§
                        Object.defineProperty(navigator, 'languages', {
                            get: () => ['zh-CN', 'zh', 'en-US', 'en']
                        });
                    '''
                })

                logger.info(f"çº¿ç¨‹ {thread_id} æˆåŠŸåˆå§‹åŒ– Edge WebDriver")
            except Exception as e:
                logger.warning(f"çº¿ç¨‹ {thread_id} Edge WebDriver åˆå§‹åŒ–å¤±è´¥: {str(e)}")

                try:
                    # æœ€åå°è¯•Firefox
                    from webdriver_manager.firefox import GeckoDriverManager

                    firefox_options = webdriver.FirefoxOptions()
                    for arg in options.arguments:
                        if not arg.startswith('--disable-dev-shm-usage') and not arg.startswith('--no-sandbox'):
                            firefox_options.add_argument(arg)
                    firefox_options.page_load_strategy = 'eager'
                    firefox_options.add_argument('--log-level=3')  # ä»…æ˜¾ç¤ºè‡´å‘½é”™è¯¯

                    # Firefoxç‰¹æœ‰çš„æ€§èƒ½è®¾ç½®
                    firefox_profile = webdriver.FirefoxProfile()
                    firefox_profile.set_preference("dom.webdriver.enabled", False)
                    firefox_profile.set_preference('useAutomationExtension', False)
                    firefox_profile.set_preference("general.useragent.override", user_agent)
                    firefox_profile.update_preferences()
                    firefox_options.profile = firefox_profile

                    driver_path = GeckoDriverManager().install()

                    service = Service(executable_path=driver_path)
                    driver = webdriver.Firefox(service=service, options=firefox_options)
                    logger.info(f"çº¿ç¨‹ {thread_id} æˆåŠŸåˆå§‹åŒ– Firefox WebDriver")
                except Exception as e:
                    logger.error(f"çº¿ç¨‹ {thread_id} æ‰€æœ‰WebDriveråˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    raise

        # å°†åˆ›å»ºçš„driverå®ä¾‹æ·»åŠ åˆ°poolä¸­
        with self._driver_pool_lock:
            self._driver_pool[thread_id] = driver

        return driver

    def get_driver(self):
        """
        è·å–å½“å‰çº¿ç¨‹çš„WebDriverå®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆå§‹åŒ–

        Returns:
            WebDriverå®ä¾‹
        """
        thread_id = threading.get_ident()

        with self._driver_pool_lock:
            driver = self._driver_pool.get(thread_id)

            # æ£€æŸ¥é©±åŠ¨æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
            if driver is not None:
                try:
                    driver.current_url  # å°è¯•è®¿é—®å±æ€§ä»¥æ£€æŸ¥é©±åŠ¨æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                except (WebDriverException, Exception) as e:
                    logger.warning(f"çº¿ç¨‹ {thread_id} çš„WebDriverå·²å¤±æ•ˆï¼Œé‡æ–°åˆå§‹åŒ–: {str(e)}")
                    driver = None

            # å¦‚æœä¸å­˜åœ¨æˆ–æ— æ•ˆï¼Œåˆ›å»ºæ–°çš„
            if driver is None:
                driver = self._init_driver(thread_id)

            return driver

    def close_driver(self, thread_id=None):
        """
        å…³é—­æŒ‡å®šçº¿ç¨‹çš„WebDriverå®ä¾‹

        Args:
            thread_id: å¯é€‰çš„çº¿ç¨‹IDï¼Œé»˜è®¤ä¸ºå½“å‰çº¿ç¨‹
        """
        if thread_id is None:
            thread_id = threading.get_ident()

        with self._driver_pool_lock:
            driver = self._driver_pool.get(thread_id)
            if driver:
                try:
                    driver.quit()
                    logger.info(f"çº¿ç¨‹ {thread_id} çš„WebDriverå·²å…³é—­")
                except Exception as e:
                    logger.warning(f"å…³é—­çº¿ç¨‹ {thread_id} çš„WebDriveræ—¶å‡ºé”™: {str(e)}")
                finally:
                    self._driver_pool.pop(thread_id, None)

    def close_all_drivers(self):
        """
        å…³é—­æ‰€æœ‰WebDriverå®ä¾‹
        """
        with self._driver_pool_lock:
            for thread_id, driver in list(self._driver_pool.items()):
                try:
                    driver.quit()
                    logger.info(f"çº¿ç¨‹ {thread_id} çš„WebDriverå·²å…³é—­")
                except Exception as e:
                    logger.warning(f"å…³é—­çº¿ç¨‹ {thread_id} çš„WebDriveræ—¶å‡ºé”™: {str(e)}")
            self._driver_pool.clear()

    def get_random_user_agent(self):
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:93.0) Gecko/20100101 Firefox/93.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:93.0) Gecko/20100101 Firefox/93.0"
        ]
        return random.choice(user_agents)

    def simulate_human_behavior(self, driver):
        """æ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸ºï¼Œå‡å°‘è¢«æ£€æµ‹ä¸ºæœºå™¨äººçš„å¯èƒ½æ€§"""
        try:
            # éšæœºç­‰å¾…
            time.sleep(random.uniform(1, 3))

            # éšæœºæ»šåŠ¨
            for _ in range(random.randint(2, 5)):
                scroll_amount = random.randint(300, 700)
                driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
                time.sleep(random.uniform(0.5, 1.5))

            # éšæœºç§»åŠ¨é¼ æ ‡(ä½¿ç”¨ActionChains)
            if random.random() > 0.5:  # 50%æ¦‚ç‡æ‰§è¡Œ
                action = ActionChains(driver)
                for _ in range(random.randint(1, 3)):
                    action.move_by_offset(random.randint(-100, 100), random.randint(-100, 100))
                    action.perform()
                    time.sleep(random.uniform(0.1, 0.5))

            logger.debug("å·²æ‰§è¡Œäººç±»è¡Œä¸ºæ¨¡æ‹Ÿ")
        except Exception as e:
            logger.warning(f"æ¨¡æ‹Ÿäººç±»è¡Œä¸ºæ—¶å‡ºé”™: {str(e)}")

    def handle_cloudflare(self, driver, timeout=30):
        """å¤„ç†Cloudflareé˜²æŠ¤é¡µé¢"""
        try:
            start_time = time.time()
            while time.time() - start_time < timeout:
                if "Just a moment..." in driver.title or "Checking your browser" in driver.page_source:
                    logger.info("æ£€æµ‹åˆ°CloudflareéªŒè¯ï¼Œç­‰å¾…é€šè¿‡...")
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´å¹¶æ¨¡æ‹Ÿå‡ æ¬¡æ»šåŠ¨
                    self.simulate_human_behavior(driver)
                    time.sleep(random.uniform(2, 3))
                else:
                    logger.info("CloudflareéªŒè¯å·²é€šè¿‡æˆ–ä¸å­˜åœ¨")
                    return True  # éªŒè¯é€šè¿‡æˆ–ä¸å­˜åœ¨éªŒè¯
            logger.warning("CloudflareéªŒè¯è¶…æ—¶")
            return False  # è¶…æ—¶ï¼ŒéªŒè¯å¤±è´¥
        except Exception as e:
            logger.error(f"å¤„ç†CloudflareéªŒè¯æ—¶å‡ºé”™: {str(e)}")
            return False

        return True  # æ²¡æœ‰CloudflareéªŒè¯é¡µé¢ï¼Œç›´æ¥è¿”å›æˆåŠŸ

    def format_exchange_rate_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%mæœˆ %d, %Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_stee_price_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y/%m/%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_shibor_rate_date(self,raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_sofr_date(self, raw_date):
        # è·å–å½“å‰å¹´ä»½
        current_year = datetime.now().year
        # æ‹¼æ¥å¹´ä»½ã€æœˆä»½å’Œæ—¥æœŸ
        full_date_str = f"{current_year}/{raw_date}"

        try:
            # è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡
            dt = datetime.strptime(full_date_str, "%Y/%m/%d")
            # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
            if platform.system() == "Windows":
                return dt.strftime("%Y/%#m/%d")
            else:  # Linux/macOS
                return dt.strftime("%Y/%-m/%d")
        except ValueError:
            print(f"æ—¥æœŸè§£æå¤±è´¥ï¼Œè¾“å…¥çš„æ—¥æœŸ {raw_date} æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ã€‚")
            return None

    def format_ester_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%m/%d/%Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_jpy_rate_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%m-%d-%Y")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_lpr_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    def format_us_interest_rate_date(self, raw_date):
        # è§£æä¸­æ–‡æœˆä»½
        dt = datetime.strptime(raw_date, "%Y-%m-%d")

        # åˆ¤æ–­æ“ä½œç³»ç»Ÿ
        if platform.system() == "Windows":
            return dt.strftime("%Y/%#m/%d")
        else:  # Linux/macOS
            return dt.strftime("%Y/%-m/%d")

    @log_execution_time
    @retry_on_timeout
    def crawl_exchange_rate(self, url):
        """ä¼˜åŒ–åçš„æ±‡ç‡æ•°æ®çˆ¬å–æ–¹æ³•ï¼ˆå¸¦è¯¦ç»†è°ƒè¯•æ—¥å¿—ï¼‰"""
        driver = self.get_driver()
        logger.info(f"å¼€å§‹çˆ¬å–æ±‡ç‡æ•°æ®ï¼š{url}")

        try:

            # è®¾ç½®è¶…æ—¶ç­–ç•¥
            driver.set_page_load_timeout(20)
            driver.implicitly_wait(5)
            wait = WebDriverWait(driver, 25, poll_frequency=1)

            try:
                logger.debug("å°è¯•åŠ è½½é¡µé¢...")
                driver.get(url)
            except TimeoutException:
                logger.warning("é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå¼ºåˆ¶åœæ­¢")
                driver.execute_script("window.stop();")

            # è¡¨æ ¼å®šä½ç­–ç•¥ä¼˜åŒ–
            try:
                logger.debug("å®šä½æ•°æ®è¡¨æ ¼...")
                table = wait.until(EC.presence_of_element_located((
                    By.XPATH, '//table[contains(@class, "freeze-column")]'
                )))
                logger.debug("è¡¨æ ¼å®šä½æˆåŠŸ")
            except TimeoutException as e:
                logger.error("âŒ è¡¨æ ¼å®šä½å¤±è´¥ï¼Œå¯èƒ½åŸå› ï¼š")
                logger.error("1. é¡µé¢ç»“æ„å·²å˜æ›´")
                logger.error("2. åçˆ¬æœºåˆ¶è§¦å‘")
                logger.error("3. ç½‘ç»œè¯·æ±‚è¢«æ‹¦æˆª")
                raise

            # æ•°æ®è¡Œè·å–ç­–ç•¥
            def _load_rows(driver):
                """å¸¦æ»šåŠ¨åŠ è½½çš„è¡Œè·å–å‡½æ•°"""
                last_height = driver.execute_script("return document.body.scrollHeight")
                for _ in range(3):  # æœ€å¤šæ»šåŠ¨3æ¬¡
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1.5)
                    new_height = driver.execute_script("return document.body.scrollHeight")
                    if new_height == last_height:
                        break
                    last_height = new_height

                rows = driver.find_elements(
                    By.CSS_SELECTOR,
                    "tr.historical-data-v2_price__atUfP:not(:empty)"
                )
                return rows if len(rows) > 5 else None  # è‡³å°‘éœ€è¦5è¡Œæ•°æ®

            try:
                logger.debug("å°è¯•è·å–æ•°æ®è¡Œ...")
                rows = wait.until(
                    lambda d: _load_rows(d) or (_load_rows(d) and False),
                    message="æ•°æ®è¡ŒåŠ è½½å¤±è´¥"
                )
                logger.info(f"è·å–åˆ° {len(rows)} è¡Œæœ‰æ•ˆæ•°æ®")
            except TimeoutException:
                logger.error("æ•°æ®è¡ŒåŠ è½½è¶…æ—¶ï¼Œå¯èƒ½åŸå› ï¼š")
                logger.error("1. æ»šåŠ¨åŠ è½½æœªè§¦å‘")
                logger.error("2. åçˆ¬éªŒè¯æœªé€šè¿‡")
                return None

            # æ•°æ®è§£æä¼˜åŒ–
            results = []
            required_columns = {"æ”¶ç›˜", "å¼€ç›˜", "é«˜", "ä½"}
            for idx, row in enumerate(rows[:10]):  # é™åˆ¶å¤„ç†å‰100è¡Œ
                try:


                    # åŠ¨æ€å®šä½å…ƒç´ 
                    date_cell = row.find_element(By.CSS_SELECTOR, "td:first-child time")
                    cells = row.find_elements(By.CSS_SELECTOR, "td:not([style*='display:none'])")


                    # æ•°æ®æ ¡éªŒ
                    if len(cells) < 5:
                        logger.debug(f"è·³è¿‡ç¬¬ {idx} è¡Œï¼Œæ•°æ®åˆ—ä¸è¶³")
                        continue

                    # æ„å»ºæ•°æ®è®°å½•
                    record = {
                        "æ—¥æœŸ": self.format_exchange_rate_date(date_cell.text),
                        "æ”¶ç›˜": cells[1].text.strip(),
                        "å¼€ç›˜": cells[2].text.strip(),
                        "é«˜": cells[3].text.strip(),
                        "ä½": cells[4].text.strip()
                    }

                    if url == 'https://cn.investing.com/rates-bonds/u.s.-10-year-bond-yield-historical-data':
                        record["æ¶¨è·Œå¹…"] = cells[5].text.strip()
                    else:
                        record["æ¶¨è·Œå¹…"] = cells[6].text.strip()


                    results.append(record)

                except StaleElementReferenceException:
                    logger.debug(f"ç¬¬ {idx} è¡Œå…ƒç´ å¤±æ•ˆï¼Œé‡æ–°è·å–ä¸­...")
                    rows = driver.find_elements(
                        By.CSS_SELECTOR,
                        "tr.historical-data-v2_price__atUfP:not(:empty)"
                    )
                    continue
                except Exception as e:
                    logger.debug(f"ç¬¬ {idx} è¡Œè§£æå¼‚å¸¸ï¼š{str(e)}")
                    continue

            logger.info(f"æˆåŠŸè§£æ {len(results)} æ¡æœ‰æ•ˆè®°å½•")
            return results

        except Exception as e:
            logger.error(f"çˆ¬å–è¿‡ç¨‹å¼‚å¸¸ï¼š{str(e)}")
            logger.debug(f"å¼‚å¸¸å †æ ˆï¼š", exc_info=True)
            return None
        finally:
            driver.quit()
            logger.debug("æµè§ˆå™¨å®ä¾‹å·²å…³é—­")


    def find_last_row(self, sheet):
        """
        æ”¹è¿›çš„æŸ¥æ‰¾æœ€åä¸€è¡Œæ–¹æ³•ï¼šé€†å‘æŸ¥æ‰¾ç¬¬ä¸€ä¸ªéç©ºè¡Œ
        """
        for row in reversed(range(1, sheet.max_row + 1)):
            if any(cell.value for cell in sheet[row]):
                return row
        return 1  # å¦‚æœå…¨ä¸ºç©ºï¼Œä»ç¬¬ä¸€è¡Œå¼€å§‹

    def write_monthly_data(self, worksheet, data, row):
        """
        å†™å…¥æœˆåº¦æ•°æ®åˆ°Excel

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            data: åŒ…å«æ•°æ®çš„å­—å…¸
            row: è¦å†™å…¥çš„è¡Œå·
        """
        # è·å–å·¥ä½œè¡¨åç§°
        sheet_name = worksheet.title

        # è·å–è¯¥å·¥ä½œè¡¨å¯¹åº”çš„åˆ—å®šä¹‰
        if sheet_name in config.COLUMN_DEFINITIONS:
            columns = config.COLUMN_DEFINITIONS[sheet_name]
        else:
            logger.warning(f"æœªæ‰¾åˆ° {sheet_name} çš„åˆ—å®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤åˆ—")
            columns = ['æ—¥æœŸ']

        # å†™å…¥æ•°æ®
        for col_idx, col_name in enumerate(columns, 1):
            value = data.get(col_name, '')
            cell = worksheet.cell(row=row, column=col_idx, value=value)
            if sheet_name == 'Import and Export' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'Money Supply' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'PPI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'CPI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'PMI' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'New Bank Loan Addition' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'US Interest Rate' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            else:
                cell.alignment = Alignment(horizontal='right')

        logger.info(f"å·²åœ¨ {sheet_name} çš„ç¬¬ {row} è¡Œå†™å…¥æœˆåº¦æ•°æ®")

    def write_daily_data(self, worksheet, data, last_row, sheet_name):
        """
        å†™å…¥æ—¥é¢‘æ•°æ®åˆ°Excel

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            data: åŒ…å«æ•°æ®çš„åˆ—è¡¨ï¼ˆé€šå¸¸æœ‰å¤šè¡Œï¼‰
            last_row: æœ€åä¸€è¡Œçš„è¡Œå·
            sheet_name: å·¥ä½œè¡¨åç§°

        Returns:
            bool: æ˜¯å¦æ›´æ–°äº†æ•°æ®
        """
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if not data or len(data) < 1:
            logger.error(f"{sheet_name}: æ•°æ®ä¸è¶³ï¼Œæ— æ³•å†™å…¥")
            return False

        # è·å–æœ€æ–°æ•°æ®çš„æ—¥æœŸ
        new_date_str = data[0].get("æ—¥æœŸ", "")
        if not new_date_str:
            logger.error(f"{sheet_name}: æ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸå­—æ®µ")
            return False

        # è·å–æœ€åä¸€è¡Œçš„æ—¥æœŸå€¼
        last_date_value = worksheet.cell(row=last_row, column=1).value

        # è§£æç°æœ‰æ—¥æœŸå’Œæ–°æ—¥æœŸä¸ºdatetimeå¯¹è±¡ï¼Œç”¨äºæ¯”è¾ƒ
        new_date_obj = None
        last_date_obj = None

        # è§£ææ–°æ—¥æœŸä¸ºdatetimeå¯¹è±¡
        try:
            if '/' in new_date_str:
                year, month, day = map(int, new_date_str.split('/'))
                new_date_obj = datetime(year, month, day)
            elif '-' in new_date_str:
                year, month, day = map(int, new_date_str.split('-'))
                new_date_obj = datetime(year, month, day)
        except Exception as e:
            logger.warning(f"{sheet_name}: è§£ææ–°æ—¥æœŸ '{new_date_str}' å¤±è´¥: {str(e)}")


        # è§£æç°æœ‰æ—¥æœŸ
        if isinstance(last_date_value, datetime):
            last_date_obj = last_date_value
        else:
            try:
                if last_date_value:
                    if sheet_name == 'SOFR':
                        month, day, year = map(int, str(last_date_value).split('/'))
                        last_date_obj = datetime(year, month, day)
                    elif sheet_name == 'Shibor':
                        year, month, day = map(int, str(last_date_value).split('-'))
                        last_date_obj = datetime(year, month, day)
                    else:
                        year, month, day = map(int, str(last_date_value).split('/'))
                        last_date_obj = datetime(year, month, day)
            except Exception as e:
                logger.warning(
                    f"{sheet_name}: è§£ææœ€åä¸€è¡Œæ—¥æœŸ '{last_date_value}' å¤±è´¥: {str(e)}"
                    f"last_date_value çš„å€¼æ˜¯: {last_date_value}ï¼Œç±»å‹æ˜¯: {type(last_date_value)} "
                )

        if new_date_obj is None or last_date_obj is None:
            # è‹¥æœ‰æ—¥æœŸå¯¹è±¡ä¸º Noneï¼Œåˆ™è®°å½•è­¦å‘Šä¿¡æ¯
            logger.warning(
                f"{sheet_name}: æ—¥æœŸå¯¹è±¡æ¯”è¾ƒå¤±è´¥ï¼Œè¯·é‡è¯•åä¸è¡Œè”ç³»ç®¡ç†å‘˜ã€‚"
                f"last_date_value çš„å€¼æ˜¯: {last_date_value}ï¼Œç±»å‹æ˜¯: {type(last_date_value)} "
                f"new_date_str çš„å€¼æ˜¯: {new_date_str}ï¼Œç±»å‹æ˜¯: {type(new_date_str)}"
            )
        # è‹¥ä¸¤ä¸ªæ—¥æœŸå¯¹è±¡éƒ½ä¸ä¸º Noneï¼Œåˆ™æ¯”è¾ƒæ—¥æœŸ
        elif new_date_obj.date() == last_date_obj.date():
            # è‹¥æ—¥æœŸç›¸åŒï¼Œåˆ™è®°å½•è°ƒè¯•ä¿¡æ¯å¹¶è¿”å› False
            logger.debug(
                f"{sheet_name}: æ—¥æœŸå¯¹è±¡æ¯”è¾ƒç›¸åŒ ({new_date_obj.date()} == {last_date_obj.date()})ï¼Œæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°"
            )
            return False

        # åœ¨æ•°æ®åˆ—è¡¨ä¸­æŸ¥æ‰¾æœ€åä¸€è¡Œæ—¥æœŸçš„ä½ç½®
        last_date_index = -1

        # ä½¿ç”¨datetimeå¯¹è±¡æ¯”è¾ƒæŸ¥æ‰¾
        if last_date_obj:
            for i, item in enumerate(data):
                item_date_str = item.get("æ—¥æœŸ", "")
                try:
                    if '/' in item_date_str:
                        year, month, day = map(int, item_date_str.split('/'))
                        item_date = datetime(year, month, day)
                    elif '-' in item_date_str:
                        year, month, day = map(int, item_date_str.split('-'))
                        item_date = datetime(year, month, day)
                    else:
                        continue

                    if item_date.date() == last_date_obj.date():
                        logger.debug(f"{sheet_name}: æ‰¾åˆ°æœ€åä¸€è¡Œæ—¥æœŸ(å¯¹è±¡æ¯”è¾ƒ): {item_date} åœ¨ç´¢å¼• {i} å³å°†æ’å…¥{i}ä¸ªæ–°æ•°æ® åˆ·æ–°æœ€åä¸€è¡Œæ•°æ®")
                        last_date_index = i
                        break
                except Exception as e:
                    logger.debug(f"{sheet_name}: è§£ææ—¥æœŸ '{item_date_str}' å¤±è´¥: {str(e)}")
                    continue

        # å¦‚æœæ‰¾åˆ°äº†æœ€åä¸€è¡Œæ—¥æœŸ
        if last_date_index != -1:
            # ç”¨æ‰¾åˆ°çš„æ•°æ®è¦†ç›–æœ€åä¸€è¡Œ
            self.write_single_daily_row(worksheet, data[last_date_index], last_row, sheet_name)
            logger.debug(f"{sheet_name}: å·²æ›´æ–°ç¬¬ {last_row} è¡Œæ•°æ®")

            # å°†æœ€åä¸€è¡Œæ—¥æœŸä¹‹å‰çš„æ•°æ®å€’åºæ’å…¥
            for i in range(last_date_index - 1, -1, -1):
                # æ’å…¥æ–°è¡Œ
                target_row = last_row + (last_date_index - i)
                self.write_single_daily_row(worksheet, data[i], target_row, sheet_name)
                logger.debug(f"{sheet_name}: å·²åœ¨ç¬¬ {target_row} è¡Œæ’å…¥æ–°æ•°æ®")

            return True
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°æœ€åä¸€è¡Œæ—¥æœŸï¼Œè®°å½•æ—¥å¿—
            logger.error(f"{sheet_name}: çˆ¬å–çš„æœ€æ–°æ•°æ®å¹¶æ²¡æœ‰åŒ¹é…ä¸Šç°æœ‰æ•°æ®ï¼Œæ— æ³•æ›´æ–°.ç°æœ‰æ•°æ®{data}ï¼Œæœ€åä¸€è¡Œæ—¥æœŸ{last_date_obj}")
            return False

    def write_single_daily_row(self, worksheet, row_data, row_num, sheet_name):
        """
        å†™å…¥å•è¡Œæ—¥é¢‘æ•°æ®

        Args:
            worksheet: Excelå·¥ä½œè¡¨å¯¹è±¡
            row_data: å•è¡Œæ•°æ®å­—å…¸
            row_num: è¦å†™å…¥çš„è¡Œå·
            sheet_name: å·¥ä½œè¡¨åç§°
        """
        # è·å–è¯¥å·¥ä½œè¡¨å¯¹åº”çš„åˆ—å®šä¹‰
        if sheet_name in config.COLUMN_DEFINITIONS:
            columns = config.COLUMN_DEFINITIONS[sheet_name]
        elif sheet_name in config.CURRENCY_PAIRS:
            # æ±‡ç‡æ•°æ®ä½¿ç”¨é€šç”¨åˆ—å®šä¹‰
            if sheet_name == 'USD 10Y':
                columns = config.COLUMN_DEFINITIONS['USD 10Y']
            else:
                columns = config.COLUMN_DEFINITIONS['CURRENCY']
        else:
            logger.warning(f"æœªæ‰¾åˆ° {sheet_name} çš„åˆ—å®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤åˆ—")
            columns = ['æ—¥æœŸ']

        # å†™å…¥æ•°æ®
        for col_idx, col_name in enumerate(columns, 1):
            value = row_data.get(col_name, '')
            if sheet_name == 'Shibor' and col_idx == 1:
                value_dt = datetime.strptime(value, '%Y/%m/%d')
                if isinstance(value_dt, datetime):
                    value = value_dt.strftime('%Y-%m-%d')
            if sheet_name == 'SOFR' and col_idx == 1:
                value_dt = datetime.strptime(value, '%Y/%m/%d')
                if isinstance(value_dt, datetime):
                    value = value_dt.strftime('%m/%d/%Y')
                    # å»æ‰æœˆä»½å’Œæ—¥æœŸçš„å‰å¯¼é›¶
                    month, day, year = value.split('/')
                    month = month.lstrip('0') if month.startswith('0') and len(month) > 1 else month
                    day = day.lstrip('0') if day.startswith('0') and len(day) > 1 else day
                    value = f"{month}/{day}/{year}"
            cell = worksheet.cell(row=row_num, column=col_idx, value=value)
            if sheet_name == 'Shibor':
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'SOFR' and col_idx == 1:
                cell.alignment = Alignment(horizontal='left')
            elif sheet_name == 'SOFR' and col_idx == 2:
                cell.alignment = Alignment(horizontal='left')
            else:
                cell.alignment = Alignment(horizontal='right')

    def update_excel(self):
        """
        æ›´æ–°ç°æœ‰Excelæ–‡ä»¶ï¼Œè¿½åŠ æ•°æ®åˆ°å¯¹åº”sheetçš„æœ€åä¸€è¡Œï¼ˆä¸²è¡Œæ‰§è¡Œç‰ˆæœ¬ï¼‰
        """
        stats = CrawlStats()  # åˆ›å»ºç»Ÿè®¡å¯¹è±¡

        try:
            results = {}
            
            # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
            total_tasks = len(config.CURRENCY_PAIRS) + len(config.DAILY_DATA_PAIRS) + len(config.MONTHLY_DATA_PAIRS)
            completed_tasks = 0

            # æ‰“å°ä»»åŠ¡æ€»è§ˆ
            logger.info("=" * 50)
            logger.info("ğŸš€ å¼€å§‹æ•°æ®çˆ¬å–ä»»åŠ¡ï¼ˆä¸²è¡Œæ‰§è¡Œæ¨¡å¼ï¼‰")
            logger.info("=" * 50)
            logger.info(f"ğŸ“Š æ±‡ç‡æ•°æ®: {len(config.CURRENCY_PAIRS)} é¡¹")
            logger.info(f"ğŸ“ˆ æ—¥é¢‘æ•°æ®: {len(config.DAILY_DATA_PAIRS)} é¡¹")
            logger.info(f"ğŸ“… æœˆåº¦æ•°æ®: {len(config.MONTHLY_DATA_PAIRS)} é¡¹")
            logger.info(f"ğŸ”„ æ€»ä»»åŠ¡æ•°: {total_tasks} é¡¹")
            logger.info("=" * 50)
            
            # åˆå§‹åŒ–ä¸€æ¬¡WebDriverå®ä¾‹
            logger.info("âš™ï¸ åˆå§‹åŒ–WebDriverå®ä¾‹...")
            driver = self._init_driver()
            
            # æ›´æ–°è¿›åº¦çš„è¾…åŠ©å‡½æ•°
            def update_progress(sheet_name, data_type, success=True, error_msg=None):
                nonlocal completed_tasks
                completed_tasks += 1
                progress = int(completed_tasks / total_tasks * 100)
                progress_bar = "â–ˆ" * (progress // 5) + "â–‘" * (20 - progress // 5)
                
                if success:
                    logger.info(f"âœ… [{progress:3d}%] |{progress_bar}| {sheet_name} ({data_type})")
                elif error_msg:
                    logger.error(f"âŒ [{progress:3d}%] |{progress_bar}| {sheet_name} ({data_type}): {error_msg}")
                else:
                    logger.warning(f"âš ï¸ [{progress:3d}%] |{progress_bar}| {sheet_name} ({data_type}): æ•°æ®ä¸ºç©º")

            # 1. å¤„ç†æ±‡ç‡æ•°æ®ï¼ˆä¸éœ€è¦WebDriverï¼‰
            logger.info("å¼€å§‹çˆ¬å–æ±‡ç‡æ•°æ®...")
            for pair, url in config.CURRENCY_PAIRS.items():
                try:
                    data = self.crawl_exchange_rate(url)
                    if data:
                        results[pair] = data
                        stats.add_success(pair)
                        update_progress(pair, "currency")
                    else:
                        stats.add_failure(pair, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                        update_progress(pair, "currency", False)
                except Exception as e:
                    stats.add_failure(pair, str(e))
                    update_progress(pair, "currency", False, str(e))

            # 2. å¤„ç†æ—¥é¢‘æ•°æ®ï¼ˆéœ€è¦WebDriverï¼‰
            logger.info("å¼€å§‹çˆ¬å–æ—¥é¢‘æ•°æ®...")
            for sheet_name, info in config.DAILY_DATA_PAIRS.items():
                try:
                    # ç›´æ¥è°ƒç”¨çˆ¬è™«æ–¹æ³•ï¼Œè€Œä¸æ˜¯é€šè¿‡_crawl_with_webdriver
                    crawler_method = getattr(self, info['crawler'])
                    data = crawler_method(info['url'])
                    
                    if data:
                        results[sheet_name] = data
                        stats.add_success(sheet_name)
                        update_progress(sheet_name, "daily")
                    else:
                        stats.add_failure(sheet_name, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                        update_progress(sheet_name, "daily", False)
                except Exception as e:
                    stats.add_failure(sheet_name, str(e))
                    update_progress(sheet_name, "daily", False, str(e))

            # 3. å¤„ç†æœˆåº¦æ•°æ®ï¼ˆéœ€è¦WebDriverï¼‰
            logger.info("å¼€å§‹çˆ¬å–æœˆåº¦æ•°æ®...")
            for sheet_name, info in config.MONTHLY_DATA_PAIRS.items():
                try:
                    # ç›´æ¥è°ƒç”¨çˆ¬è™«æ–¹æ³•ï¼Œè€Œä¸æ˜¯é€šè¿‡_crawl_with_webdriver
                    crawler_method = getattr(self, info['crawler'])
                    data = crawler_method(info['url'])
                    
                    if data:
                        # å¯¹äºæœˆåº¦æ•°æ®ï¼Œåªä¿ç•™ç¬¬ä¸€è¡Œ
                        if isinstance(data, list) and len(data) > 0:
                            results[sheet_name] = data[0]
                        else:
                            results[sheet_name] = data
                        stats.add_success(sheet_name)
                        update_progress(sheet_name, "monthly")
                    else:
                        stats.add_failure(sheet_name, "çˆ¬å–è¿”å›ç©ºæ•°æ®")
                        update_progress(sheet_name, "monthly", False)
                except Exception as e:
                    stats.add_failure(sheet_name, str(e))
                    update_progress(sheet_name, "monthly", False, str(e))

            # å…³é—­WebDriverå®ä¾‹
            logger.info("çˆ¬å–ä»»åŠ¡å®Œæˆï¼Œå…³é—­WebDriverå®ä¾‹...")
            self.close_driver()
            
            logger.info("=" * 50)
            logger.info("ğŸ æ•°æ®çˆ¬å–å®Œæˆï¼Œå‡†å¤‡æ›´æ–°Excelæ–‡ä»¶...")

            # 4. æ›´æ–°Excelæ–‡ä»¶
            logger.info("å¼€å§‹æ›´æ–°Excelæ–‡ä»¶...")
            excel_path = config.EXCEL_OUTPUT_PATH
            logger.info(f"ğŸ“‚ æ‰“å¼€Excelæ–‡ä»¶: {os.path.basename(excel_path)}")

            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
            if not os.path.exists(excel_path):
                raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}ã€‚è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨äºæ­£ç¡®çš„ä½ç½®ã€‚")

            wb = load_workbook(excel_path)

            updated_sheets = []  # è®°å½•å·²æ›´æ–°çš„å·¥ä½œè¡¨

            # æ›´æ–°å„ä¸ªsheet
            excel_updates = []
            for sheet_name, data in results.items():
                if not data:
                    stats.add_skipped(sheet_name, "æ•°æ®ä¸ºç©º")
                    continue

                if sheet_name not in wb.sheetnames:
                    stats.add_skipped(sheet_name, "å·¥ä½œè¡¨ä¸å­˜åœ¨")
                    logger.warning(f"âš ï¸ å·¥ä½œè¡¨ {sheet_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")
                    continue

                ws = wb[sheet_name]

                # æŸ¥æ‰¾æœ€åä¸€è¡Œæ•°æ®
                last_row = self.find_last_row(ws)


                # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹æ³•
                if sheet_name in config.MONTHLY_DATA_PAIRS:
                    # æœˆåº¦æ•°æ®å¤„ç†
                    new_date = data.get("æ—¥æœŸ", "")
                    if not new_date:
                        stats.add_skipped(sheet_name, "æ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸå­—æ®µ")
                        continue

                    # è·å–æœ€åä¸€è¡Œçš„æ—¥æœŸå€¼
                    last_date_value = ws.cell(row=last_row, column=1).value

                    # å¯¹Import and Exportè¿›è¡Œç‰¹æ®Šå¤„ç†
                    if sheet_name == 'Import and Export':
                        # å³ä½¿æ—¥æœŸç›¸åŒï¼Œä¹Ÿéœ€è¦æ£€æŸ¥æ•°æ®æ˜¯å¦ä»"-"æ›´æ–°ä¸ºå…·ä½“æ•°å€¼
                        need_update = False

                        # å¦‚æœæ—¥æœŸä¸åŒï¼Œç›´æ¥æ›´æ–°
                        if str(last_date_value) != str(new_date):
                            need_update = True
                        else:
                            # æ—¥æœŸç›¸åŒï¼Œæ£€æŸ¥å„åˆ—æ•°æ®æ˜¯å¦æœ‰ä»"-"æ›´æ–°ä¸ºå…·ä½“æ•°å€¼çš„æƒ…å†µ
                            columns = config.COLUMN_DEFINITIONS[sheet_name]
                            for col_idx, col_name in enumerate(columns, 1):
                                if col_name == 'æ—¥æœŸ':
                                    continue

                                # è·å–Excelä¸­çš„å½“å‰å€¼
                                current_value = ws.cell(row=last_row, column=col_idx).value
                                # è·å–æ–°æ•°æ®ä¸­çš„å€¼
                                new_value = data.get(col_name, '')

                                # æ£€æŸ¥æ˜¯å¦ä»"-"æ›´æ–°ä¸ºå…·ä½“æ•°å€¼
                                if (current_value == '-' or current_value == '') and new_value != '-' and new_value != '':
                                    need_update = True
                                    break

                        if need_update:
                            self.write_monthly_data(ws, data, last_row)  # è¦†ç›–å½“å‰è¡Œ
                            excel_updates.append(sheet_name)
                            updated_sheets.append(sheet_name)
                            logger.info(f"ğŸ“ æ›´æ–° {sheet_name}: {new_date}")
                        else:
                            logger.info(f"âœ“ {sheet_name} æ•°æ®å·²æ˜¯æœ€æ–°")
                    else:
                        # å…¶ä»–æœˆåº¦æ•°æ®çš„å¸¸è§„å¤„ç†
                        if str(last_date_value) != str(new_date):
                            self.write_monthly_data(ws, data, last_row + 1)
                            excel_updates.append(sheet_name)
                            updated_sheets.append(sheet_name)
                            logger.info(f"ğŸ“ æ›´æ–° {sheet_name}: {new_date}")
                        else:
                            logger.info(f"âœ“ {sheet_name} æ•°æ®å·²æ˜¯æœ€æ–°")
                else:
                    # æ—¥é¢‘æ•°æ®å¤„ç†ï¼ˆåŒ…æ‹¬æ±‡ç‡æ•°æ®ï¼‰
                    update_result = self.write_daily_data(ws, data, last_row, sheet_name)
                    if update_result:
                        excel_updates.append(sheet_name)
                        updated_sheets.append(sheet_name)
                        logger.info(f"ğŸ“ æ›´æ–° {sheet_name}")

            # æ‰“å°ç»Ÿè®¡æ‘˜è¦
            logger.info("=" * 50)
            stats.print_summary()

            # ä¿å­˜Excelæ–‡ä»¶
            if excel_updates:
                logger.info(f"ğŸ’¾ ä¿å­˜Excelæ–‡ä»¶: {os.path.basename(excel_path)}")
                try:
                    wb.save(excel_path)
                    logger.info(f"âœ… Excelæ–‡ä»¶ä¿å­˜æˆåŠŸï¼Œå·²æ›´æ–° {len(updated_sheets)} ä¸ªå·¥ä½œè¡¨")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                    return False
            else:
                logger.info("â„¹ï¸ æ‰€æœ‰å·¥ä½œè¡¨æ•°æ®å‡å·²æ˜¯æœ€æ–°ï¼ŒExcelæ–‡ä»¶æœªåšä¿®æ”¹")

            return results
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°Excelè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
            return False
        finally:
            # ç¡®ä¿å…³é—­æ‰€æœ‰WebDriverå®ä¾‹
            self.close_all_drivers()

    def _crawl_with_webdriver(self, sheet_name, info, is_monthly=False):
        """
        ä½¿ç”¨WebDriverçˆ¬å–æ•°æ®çš„è¾…åŠ©æ–¹æ³•ï¼Œæ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹çš„WebDriverå®ä¾‹

        Args:
            sheet_name: å·¥ä½œè¡¨åç§°
            info: åŒ…å«çˆ¬è™«æ–¹æ³•å’ŒURLçš„ä¿¡æ¯å­—å…¸
            is_monthly: æ˜¯å¦ä¸ºæœˆåº¦æ•°æ®

        Returns:
            çˆ¬å–çš„æ•°æ®
        """
        try:
            # è·å–å½“å‰çº¿ç¨‹çš„WebDriver
            driver = self.get_driver()

            # è°ƒç”¨å¯¹åº”çš„çˆ¬è™«æ–¹æ³•
            crawler_method = getattr(self, info['crawler'])
            data = crawler_method(info['url'])

            return data
        except Exception as e:
            logger.error(f"çˆ¬å– {sheet_name} æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            raise

    @log_execution_time
    @retry_on_timeout
    def crawl_steel_price(self, url):
        """
        çˆ¬å–é’¢é“ä»·æ ¼æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # é’ˆå¯¹ç‰¹å®šç«™ç‚¹å¢åŠ è¶…æ—¶æ—¶é—´
            if "mysteel.com" in url:  # Steel priceç«™ç‚¹
                driver.set_page_load_timeout(60)  # å¢åŠ åˆ°60ç§’
                wait = WebDriverWait(driver, 30)  # å¢åŠ ç­‰å¾…æ—¶é—´
            elif "euribor-rates.eu" in url:  # ESTERç«™ç‚¹
                driver.set_page_load_timeout(60)
                wait = WebDriverWait(driver, 30)
            else:
                driver.set_page_load_timeout(20)
                wait = WebDriverWait(driver, 10)

            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait.until(EC.element_to_be_clickable((By.XPATH, '//span[text()="ç›¸å¯¹ä»·æ ¼æŒ‡æ•°èµ°åŠ¿å›¾"]'))).click()

            # ç­‰å¾…æ•°æ®å®Œå…¨åŠ è½½
            wait.until(EC.presence_of_element_located((By.XPATH, '//td[contains(text(),"/") and string-length(text())>8]')))

            # è·å–è¡¨æ ¼å¼•ç”¨
            table = driver.find_element(By.XPATH, '//table[contains(@class,"detailTab")]')

            # å•æ¬¡è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ® - ä¿®æ”¹ä¸ºè·å–å‰10è¡Œ
            rows = table.find_elements(By.XPATH, './/tbody/tr[position()<=10]')
            data = []

            for row in rows:
                try:
                    # å®æ—¶è·å–å½“å‰è¡Œå…ƒç´ 
                    cells = row.find_elements(By.XPATH, './/td[not(contains(@style,"none"))]')


                    # æ•°æ®æ ¡éªŒ
                    if len(cells) < 10:
                        logger.debug(f"Steel price: è·³è¿‡æ— æ•ˆè¡Œï¼Œåˆ—æ•°ï¼š{len(cells)}")
                        continue

                    # ç«‹å³æå–æ–‡æœ¬å†…å®¹
                    cell_texts = [cell.text for cell in cells]


                    # åŠ¨æ€æ˜ å°„å­—æ®µ
                    item = {
                        "æ—¥æœŸ": self.format_stee_price_date(cells[0].get_attribute('textContent').strip()),
                        "æœ¬æ—¥": cells[1].text.strip(),
                        "æ˜¨æ—¥": cells[2].text.strip(),
                        "æ—¥ç¯æ¯”": cells[3].text.strip(),
                        "ä¸Šå‘¨": cells[4].text.strip(),
                        "å‘¨ç¯æ¯”": cells[5].text.strip(),
                        "ä¸Šæœˆåº¦": cells[6].text.strip(),
                        "ä¸ä¸Šæœˆæ¯”": cells[7].text.strip(),
                        "å»å¹´åŒæœŸ": cells[8].text.strip(),
                        "ä¸å»å¹´æ¯”": cells[9].text.strip(),
                    }
                    data.append(item)

                except StaleElementReferenceException:
                    logger.debug("Steel price: æ£€æµ‹åˆ°å…ƒç´ è¿‡æœŸï¼Œé‡æ–°è·å–è¡¨æ ¼æ•°æ®...")
                    # é‡æ–°è·å–è¡¨æ ¼å’Œè¡Œ
                    table = driver.find_element(By.XPATH, '//table[contains(@class,"detailTab")]')
                    rows = table.find_elements(By.XPATH, './/tbody/tr[position()<=10]')
                    continue
                except Exception as e:
                    logger.debug(f"Steel price: ç¬¬ {idx} è¡Œè§£æå¼‚å¸¸ï¼š{str(e)}")
                    continue

            logger.debug(f"æˆåŠŸæŠ“å– Steel price æ•°æ®: {len(data)} æ¡è®°å½•")
            return data

        except TimeoutException:
            logger.error("Steel price: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Steel price: çˆ¬å–æ•°æ®å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_shibor_rate(self, url):
        """
        çˆ¬å–Shiboråˆ©ç‡æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'shibor-tendays-show-data')))

            # åˆå§‹åŒ–ç»“æœæ•°ç»„
            result_list = []
            row_count = 0

            for row in table.find_elements(By.CSS_SELECTOR, "tr:has(td)"):
                if row_count >= 10:  # ä¿®æ”¹ä¸ºè·å–å‰10è¡Œæ•°æ®
                    break  # åªå–å‰10è¡Œæ•°æ®

                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) < 9:
                    continue

                # è§£ææ•°æ®
                current_record = {}
                current_record['æ—¥æœŸ'] = self.format_shibor_rate_date(cells[0].text.strip())
                terms = ['O/N', '1W', '2W', '1M', '3M', '6M', '9M', '1Y']

                for i, term in enumerate(terms):
                    current_record[term] = cells[i + 1].text.strip()

                result_list.append(current_record)
                row_count += 1

            logger.debug(f"æˆåŠŸæŠ“å– Shibor æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Shibor: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Shibor: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_lpr(self, url):
        """
        çˆ¬å–LPRæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'lpr-ten-days-table')))

            # æå–å…³é”®æ•°æ®
            rows = table.find_elements(By.CSS_SELECTOR, "tr")
            # è·³è¿‡è¡¨å¤´è¡Œ
            data_rows = rows[3:]

            # åˆå§‹åŒ–ç»“æœæ•°ç»„
            result_list = []
            row_index = 0

            for row in data_rows:
                if row_index >= 10:  # ä¿®æ”¹ä¸ºè·å–å‰10è¡Œæ•°æ®
                    break

                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) < 3:
                    continue

                date = self.format_lpr_date(cells[0].text.strip())
                term_1y = cells[1].text.strip()
                term_5y = cells[2].text.strip()

                current_record = {
                    "æ—¥æœŸ": date,
                    "1Y": term_1y,
                    "5Y": term_5y,
                    "PBOC_(6M-1Y)": 4.35,
                    "rowPBOC_(>5Y)": 4.9
                }
                result_list.append(current_record)
                row_index += 1

            logger.debug(f"æˆåŠŸæŠ“å– LPR æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("LPR: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"LPR: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_sofr(self, url):
        """
        çˆ¬å–SOFRæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(20)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 10)
            table = wait.until(EC.presence_of_element_located((By.ID, 'pr_id_1-table')))

            # è·å–æ‰€æœ‰æ•°æ®è¡Œ
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # ç¡®ä¿åˆ—æ•°è¶³å¤Ÿ
                if len(cells) < 7:
                    logger.debug(f"SOFR: æ£€æµ‹åˆ°ä¸å®Œæ•´è¡Œï¼Œå®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # æŒ‰é¡ºåºæå–å­—æ®µ
                record = {
                    "æ—¥æœŸ": self.format_sofr_date(cells[0].text.strip()),
                    "Rate Type": 'SOFR',
                    "RATE(%)": cells[1].text.strip(),
                    "1ST PERCENTILE(%)": cells[2].text.strip(),
                    "25TH PERCENTILE(%)": cells[3].text.strip(),
                    "75TH PERCENTILE(%)": cells[4].text.strip(),
                    "99TH PERCENTILE(%)": cells[5].text.strip(),
                    "VOLUME ($Billions)": cells[6].text.strip()
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– SOFR æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("SOFR: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"SOFR: æ•°æ®æŠ“å–å¤±è´¥: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_ester(self, url):
        """
        çˆ¬å–ESTERæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
            wait = WebDriverWait(driver, 15)

            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            tables = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "table.table-striped")))
            if not tables:
                logger.error("ESTER: æœªæ‰¾åˆ°ç›®æ ‡è¡¨æ ¼")
                return None

            table = tables[0]  # å–ç¬¬ä¸€ä¸ªè¡¨æ ¼

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            logger.debug(f"ESTER: æ‰¾åˆ°æ•°æ®è¡Œæ•°ï¼š{len(rows)}")

            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 2:
                    logger.debug(f"ESTER: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": self.format_ester_date(cells[0].get_attribute('textContent').strip()),
                    "value": cells[1].get_attribute('textContent').strip().replace(' %', '')
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– ESTER æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("ESTER: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"ESTER: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_jpy_rate(self, url):
        """
        çˆ¬å–JPYåˆ©ç‡æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 15)

            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table[class='table ']")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰10è¡Œæ•°æ®
            for row in rows[:10]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 2:
                    logger.debug(f"JPY rate: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": self.format_jpy_rate_date(cells[0].get_attribute('textContent').strip()),
                    "value": cells[1].get_attribute('textContent').strip().replace(' %', '')
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– JPY rate æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("JPY rate: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"JPY rate: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_us_interest_rate(self, url):
        """
        çˆ¬å–ç¾å›½åˆ©ç‡æ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 4:
                    logger.debug(f"US Interest Rate: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å‰å€¼": cells[1].text.strip(),
                    "ç°å€¼": cells[2].text.strip(),
                    "å‘å¸ƒæ—¥æœŸ": self.format_us_interest_rate_date(cells[3].text.strip()),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– US Interest Rate æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("US Interest Rate: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"US Interest Rate: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_import_export(self, url):
        """
        çˆ¬å–è¿›å‡ºå£è´¸æ˜“æ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 11:
                    logger.debug(f"Import Export: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆå‡ºå£é¢é‡‘é¢": cells[1].text.strip(),
                    "å½“æœˆå‡ºå£é¢åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "å½“æœˆå‡ºå£é¢ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "å½“æœˆè¿›å£é¢é‡‘é¢": cells[4].text.strip(),
                    "å½“æœˆè¿›å£é¢åŒæ¯”å¢é•¿": cells[5].text.strip(),
                    "å½“æœˆè¿›å£é¢ç¯æ¯”å¢é•¿": cells[6].text.strip(),
                    "ç´¯è®¡å‡ºå£é¢é‡‘é¢": cells[7].text.strip(),
                    "ç´¯è®¡å‡ºå£é¢åŒæ¯”å¢é•¿": cells[8].text.strip(),
                    "ç´¯è®¡è¿›å£é¢é‡‘é¢": cells[9].text.strip(),
                    "ç´¯è®¡è¿›å£é¢åŒæ¯”å¢é•¿": cells[10].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– Import and Export æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Import Export: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Import Export: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_money_supply(self, url):
        """
        çˆ¬å–è´§å¸ä¾›åº”æ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 10:
                    logger.debug(f"Money Supply: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "M2æ•°é‡": cells[1].text.strip(),
                    "M2åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "M2ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "M1æ•°é‡": cells[4].text.strip(),
                    "M1åŒæ¯”å¢é•¿": cells[5].text.strip(),
                    "M1ç¯æ¯”å¢é•¿": cells[6].text.strip(),
                    "M0æ•°é‡": cells[7].text.strip(),
                    "M0åŒæ¯”å¢é•¿": cells[8].text.strip(),
                    "M0ç¯æ¯”å¢é•¿": cells[9].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– Money Supply æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("Money Supply: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"Money Supply: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_ppi(self, url):
        """
        çˆ¬å–ppiæ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 4:
                    logger.debug(f"PPI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆ": cells[1].text.strip(),
                    "å½“æœˆåŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "ç´¯è®¡": cells[3].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– PPI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("PPI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"PPI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_cpi(self, url):
        """
        çˆ¬å–cpiæ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 13:
                    logger.debug(f"CPI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å…¨å›½å½“æœˆ": cells[1].text.strip(),
                    "å…¨å›½åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "å…¨å›½ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "å…¨å›½ç´¯è®¡": cells[4].text.strip(),
                    "åŸå¸‚å½“æœˆ": cells[5].text.strip(),
                    "åŸå¸‚åŒæ¯”å¢é•¿": cells[6].text.strip(),
                    "åŸå¸‚ç¯æ¯”å¢é•¿": cells[7].text.strip(),
                    "åŸå¸‚ç´¯è®¡": cells[8].text.strip(),
                    "å†œæ‘å½“æœˆ": cells[9].text.strip(),
                    "å†œæ‘åŒæ¯”å¢é•¿": cells[10].text.strip(),
                    "å†œæ‘ç¯æ¯”å¢é•¿": cells[11].text.strip(),
                    "å†œæ‘ç´¯è®¡": cells[12].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– CPI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("CPI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"CPI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_pmi(self, url):
        """
        çˆ¬å–pmiæ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 5:
                    logger.debug(f"PMI: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½•
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "åˆ¶é€ ä¸šæŒ‡æ•°": cells[1].text.strip(),
                    "åˆ¶é€ ä¸šåŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "éåˆ¶é€ ä¸šæŒ‡æ•°": cells[3].text.strip(),
                    "éåˆ¶é€ ä¸šåŒæ¯”å¢é•¿": cells[4].text.strip(),
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– PMI æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("PMI: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"PMI: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

    @log_execution_time
    @retry_on_timeout
    def crawl_new_bank_loan_addition(self, url):
        """
        çˆ¬å– ä¸­å›½ æ–°å¢ä¿¡è´·æ•°æ®
        """
        driver = self.get_driver()
        logger.debug(f"æ­£åœ¨è¯·æ±‚URL: {url}")

        try:
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.get(url)

            # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼Œå‡å°‘å›ºå®šç­‰å¾…æ—¶é—´
            wait = WebDriverWait(driver, 15)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-model")))

            # è·å–æœ‰æ•ˆæ•°æ®è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            rows = table.find_elements(By.CSS_SELECTOR, "tr:has(td)")
            result_list = []

            # å¤„ç†å‰ä¸¤è¡Œæ•°æ®
            for row in rows[:2]:
                cells = row.find_elements(By.TAG_NAME, "td")

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(cells) != 6:
                    logger.debug(f"New Bank Loan: å¼‚å¸¸è¡Œæ•°æ®ï¼Œè·³è¿‡ã€‚å®é™…åˆ—æ•°ï¼š{len(cells)}")
                    continue

                # åˆ›å»ºæ ¼å¼åŒ–è®°å½• - ä¿®å¤å­—æ®µåç§°ï¼Œé¿å…é‡å¤çš„"åŒæ¯”å¢é•¿"
                record = {
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "å½“æœˆ": cells[1].text.strip(),
                    "åŒæ¯”å¢é•¿": cells[2].text.strip(),
                    "ç¯æ¯”å¢é•¿": cells[3].text.strip(),
                    "ç´¯è®¡": cells[4].text.strip(),
                    "ç´¯è®¡åŒæ¯”å¢é•¿": cells[5].text.strip(),  # ä¿®æ”¹ä¸º"ç´¯è®¡åŒæ¯”å¢é•¿"ä»¥åŒºåˆ†
                }
                result_list.append(record)

            logger.debug(f"æˆåŠŸæŠ“å– New Bank Loan Addition æ•°æ®: {len(result_list)} æ¡è®°å½•")
            return result_list

        except TimeoutException:
            logger.error("New Bank Loan: é¡µé¢åŠ è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–URLæ˜¯å¦æ­£ç¡®")
            return None
        except Exception as e:
            logger.error(f"New Bank Loan: æ•°æ®æŠ“å–å¼‚å¸¸: {str(e)}")
            return None

if __name__ == "__main__":
    def main():
        """ä¸»å‡½æ•°"""
        import argparse

        parser = argparse.ArgumentParser(description='å¸‚åœºæ•°æ®çˆ¬å–å·¥å…·')
        parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ—¥å¿—')
        args = parser.parse_args()

        # è®¾ç½®æ—¥å¿—çº§åˆ«
        setup_logging(debug=args.debug)

        if args.debug:
            logger.info("å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œå°†æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")
        else:
            logger.info("ä½¿ç”¨æ ‡å‡†æ—¥å¿—çº§åˆ«ã€‚ä½¿ç”¨ --debug å‚æ•°å¯æŸ¥çœ‹è¯¦ç»†æ—¥å¿—")

        print("==================================================")
        print("å¸‚åœºæ•°æ®çˆ¬å–å·¥å…·")
        print("==================================================")

        analyzer = MarketDataAnalyzer()

        logger.info("å¼€å§‹æ›´æ–°å¸‚åœºæ•°æ®...")
        analyzer.update_excel()

        print("\nç¨‹åºè¿è¡Œå®Œæˆ")

    main()
